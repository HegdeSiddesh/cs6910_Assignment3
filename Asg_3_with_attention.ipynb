{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HegdeSiddesh/cs6910_Assignment3/blob/main/Asg_3_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-oWJRqX0rp2R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f62f2ac2-9d9b-40b4-bec4-7de79cd7658d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wandb\n",
            "  Downloading wandb-0.12.16-py2.py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 5.1 MB/s \n",
            "\u001b[?25hCollecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting setproctitle\n",
            "  Downloading setproctitle-1.2.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.27-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from wandb) (57.4.0)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (3.17.3)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.23.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.8.2)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from wandb) (3.13)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (2.3)\n",
            "Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/dist-packages (from wandb) (1.15.0)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.11-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 39.5 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb) (4.2.0)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.0.0->wandb) (1.24.3)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=9e823ad802a71dc1b5d4e3a256b3052f0fb8a33c5b7472c70dce351bce45fead\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built pathtools\n",
            "Installing collected packages: smmap, gitdb, shortuuid, setproctitle, sentry-sdk, pathtools, GitPython, docker-pycreds, wandb\n",
            "Successfully installed GitPython-3.1.27 docker-pycreds-0.4.0 gitdb-4.0.9 pathtools-0.1.2 sentry-sdk-1.5.11 setproctitle-1.2.3 shortuuid-1.0.8 smmap-5.0.0 wandb-0.12.16\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "!pip install --upgrade wandb\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "p7m2vLypLTX6",
        "outputId": "e7883e1b-d1b2-440b-9262-b513986761f6"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dlawNlDsD9W",
        "outputId": "bf414e3a-4e59-4dc0-cecd-7f896693840a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-06 08:07:18--  https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.26.128, 172.217.203.128, 172.253.123.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.26.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2008340480 (1.9G) [application/x-tar]\n",
            "Saving to: ‘dakshina_dataset_v1.0.tar’\n",
            "\n",
            "dakshina_dataset_v1 100%[===================>]   1.87G   253MB/s    in 7.5s    \n",
            "\n",
            "2022-05-06 08:07:25 (256 MB/s) - ‘dakshina_dataset_v1.0.tar’ saved [2008340480/2008340480]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Download and unzip the Dakshina dataset \n",
        "!wget https://storage.googleapis.com/gresearch/dakshina/dakshina_dataset_v1.0.tar\n",
        "!tar -xf '/content/dakshina_dataset_v1.0.tar'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "ssqhbmxSMqWp",
        "outputId": "998223bd-7e84-4e95-873a-53d9ad72b726"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhithesh\u001b[0m (\u001b[33mhithesh-sidhesh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_155319-fc6non1d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/fc6non1d\" target=\"_blank\">Question_5</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/fc6non1d?jupyter=true\" style=\"border:none;width:100%;height:420px;display:none;\"></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ff9c424aed0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "wandb.init(project=\"CS6910-Assignment_3-sweep-Tamil\", entity=\"hithesh-sidhesh\", name=\"Question_5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ky6kbChVs-d9"
      },
      "outputs": [],
      "source": [
        "def load_data(path):\n",
        "    with open(path) as fil:\n",
        "        data = pd.read_csv(fil,sep='\\t',header=None,names=[\"Tamil\",\"English\",\"\"],skip_blank_lines=True,index_col=None)\n",
        "    data = data[data['Tamil'].notna()]\n",
        "    data = data[data['English'].notna()]\n",
        "    data = data[['Tamil','English']]\n",
        "    return data\n",
        "\n",
        "train = load_data(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.train.tsv\")\n",
        "val = load_data(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.dev.tsv\")\n",
        "test = load_data(\"/content/dakshina_dataset_v1.0/ta/lexicons/ta.translit.sampled.test.tsv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7o9DZ3388E-N"
      },
      "outputs": [],
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 25  # Number of epochs to train for.\n",
        "latent_dim = 256  # Latent dimensionality of the encoding space."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TP489yXIV_o4"
      },
      "outputs": [],
      "source": [
        "x = train['English'].values\n",
        "y = train['Tamil'].values\n",
        "# We use \"tab\" as the \"start sequence\" character for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "y = \"\\t\"+y+\"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "b72oXuWpbGCm"
      },
      "outputs": [],
      "source": [
        "train_input_words = [str(word) for word in list(train['English'])]\n",
        "train_target_words = [\"\\t\" + str(word) + \"\\n\" for word in list(train['Tamil'])]\n",
        "\n",
        "val_input_words = [str(word) for word in list(val['English'])]\n",
        "val_target_words = [\"\\t\" + str(word) + \"\\n\" for word in list(val['Tamil'])]\n",
        "\n",
        "test_input_words = [str(word) for word in list(test['English'])]\n",
        "test_target_words = [\"\\t\" + str(word) + \"\\n\" for word in list(test['Tamil'])]\n",
        "\n",
        "    # for train_word in train_input_words:\n",
        "    #     for char in train_word:\n",
        "    #         input_characters.add(char)\n",
        "\n",
        "    # for val_word in val_input_words:\n",
        "    #     for char in val_word:\n",
        "    #         input_characters.add(char)\n",
        "\n",
        "    # for test_word in test_input_words:\n",
        "    #     for char in test_word:\n",
        "    #         input_characters.add(char)\n",
        "\n",
        "    # for train_word in train_target_words:\n",
        "    #     for char in train_word:\n",
        "    #         target_characters.add(char)\n",
        "\n",
        "    # for val_word in val_target_words:\n",
        "    #     for char in val_word:\n",
        "    #         target_characters.add(char)\n",
        "\n",
        "    # for test_word in test_target_words:\n",
        "    #     for char in test_word:\n",
        "    #         target_characters.add(char)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7alRIOMSF7N",
        "outputId": "a3accc7c-e2c5-4371-cc21-5d31be99782a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 68215\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for inputs: 30\n",
            "Max sequence length for outputs: 28\n",
            "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, ' ': 26}\n",
            "{'\\t': 0, '\\n': 1, 'ஃ': 2, 'அ': 3, 'ஆ': 4, 'இ': 5, 'ஈ': 6, 'உ': 7, 'ஊ': 8, 'எ': 9, 'ஏ': 10, 'ஐ': 11, 'ஒ': 12, 'ஓ': 13, 'க': 14, 'ங': 15, 'ச': 16, 'ஜ': 17, 'ஞ': 18, 'ட': 19, 'ண': 20, 'த': 21, 'ந': 22, 'ன': 23, 'ப': 24, 'ம': 25, 'ய': 26, 'ர': 27, 'ற': 28, 'ல': 29, 'ள': 30, 'ழ': 31, 'வ': 32, 'ஷ': 33, 'ஸ': 34, 'ஹ': 35, 'ா': 36, 'ி': 37, 'ீ': 38, 'ு': 39, 'ூ': 40, 'ெ': 41, 'ே': 42, 'ை': 43, 'ொ': 44, 'ோ': 45, 'ௌ': 46, '்': 47, ' ': 48}\n"
          ]
        }
      ],
      "source": [
        "input_characters = set()\n",
        "target_characters = set()\n",
        "\n",
        "for i in range(len(x)):\n",
        "  input_characters.update(list(str(x[i])))\n",
        "  target_characters.update(list(str(y[i])))\n",
        "\n",
        "  # input_characters=list(set(input_characters+list(str(x[i]))))\n",
        "  # target_characters=list(set(target_characters+list(str(y[i]))))\n",
        "\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "\n",
        "# add the space character to both\n",
        "input_characters.append(\" \")\n",
        "target_characters.append(\" \")\n",
        "\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "\n",
        "input_length=[]\n",
        "target_length=[]\n",
        "for i in range(len(x)):\n",
        "  input_length.append(len(str(x[i])))\n",
        "  target_length.append(len(str(y[i])))\n",
        "\n",
        "max_encoder_seq_length = max(input_length)\n",
        "max_decoder_seq_length = max(target_length)\n",
        "\n",
        "print(\"Number of samples:\", len(x))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "print(input_token_index)\n",
        "print(target_token_index)\n",
        "encoder_input_data = np.zeros((len(x), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
        "decoder_input_data = np.zeros((len(x), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "decoder_target_data = np.zeros((len(x), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(x, y)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wsi1yYZYaVjc",
        "outputId": "e81942ff-4238-4fb1-f3dd-24f954ceb143"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68215, 30, 27)\n"
          ]
        }
      ],
      "source": [
        "print(encoder_input_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4c9SsGTwlcjR"
      },
      "outputs": [],
      "source": [
        "#Embedding validation data\n",
        "x_val = val['English'].values\n",
        "y_val = val['Tamil'].values\n",
        "# We use \"tab\" as the \"start sequence\" character for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "y_val = \"\\t\"+y_val+\"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OPEuR3X2r8V8"
      },
      "outputs": [],
      "source": [
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJgI3viNob-6",
        "outputId": "9cc93c2a-fe46-4e32-e2f7-18b633052fb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in validation set: 6827\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for validation inputs: 23\n",
            "Max sequence length for valiation outputs: 22\n",
            "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, ' ': 26}\n",
            "{'\\t': 0, '\\n': 1, 'ஃ': 2, 'அ': 3, 'ஆ': 4, 'இ': 5, 'ஈ': 6, 'உ': 7, 'ஊ': 8, 'எ': 9, 'ஏ': 10, 'ஐ': 11, 'ஒ': 12, 'ஓ': 13, 'க': 14, 'ங': 15, 'ச': 16, 'ஜ': 17, 'ஞ': 18, 'ட': 19, 'ண': 20, 'த': 21, 'ந': 22, 'ன': 23, 'ப': 24, 'ம': 25, 'ய': 26, 'ர': 27, 'ற': 28, 'ல': 29, 'ள': 30, 'ழ': 31, 'வ': 32, 'ஷ': 33, 'ஸ': 34, 'ஹ': 35, 'ா': 36, 'ி': 37, 'ீ': 38, 'ு': 39, 'ூ': 40, 'ெ': 41, 'ே': 42, 'ை': 43, 'ொ': 44, 'ோ': 45, 'ௌ': 46, '்': 47, ' ': 48}\n"
          ]
        }
      ],
      "source": [
        "val_input_characters = set()\n",
        "val_target_characters = set()\n",
        "\n",
        "for i in range(len(x_val)):\n",
        "  val_input_characters.update(list(str(x_val[i])))\n",
        "  val_target_characters.update(list(str(y_val[i])))\n",
        "\n",
        "  # input_characters=list(set(input_characters+list(str(x[i]))))\n",
        "  # target_characters=list(set(target_characters+list(str(y[i]))))\n",
        "\n",
        "val_input_characters = sorted(list(val_input_characters))\n",
        "val_target_characters = sorted(list(val_target_characters))\n",
        "\n",
        "# add the space character to both\n",
        "val_input_characters.append(\" \")\n",
        "val_target_characters.append(\" \")\n",
        "\n",
        "val_num_encoder_tokens = len(val_input_characters)\n",
        "val_num_decoder_tokens = len(val_target_characters)\n",
        "\n",
        "val_input_length=[]\n",
        "val_target_length=[]\n",
        "for i in range(len(x_val)):\n",
        "  val_input_length.append(len(str(x_val[i])))\n",
        "  val_target_length.append(len(str(y_val[i])))\n",
        "\n",
        "val_max_encoder_seq_length = max(val_input_length)\n",
        "val_max_decoder_seq_length = max(val_target_length)\n",
        "\n",
        "print(\"Number of samples in validation set:\", len(x_val))\n",
        "print(\"Number of unique input tokens:\", val_num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", val_num_decoder_tokens)\n",
        "print(\"Max sequence length for validation inputs:\", val_max_encoder_seq_length)\n",
        "print(\"Max sequence length for valiation outputs:\", val_max_decoder_seq_length)\n",
        "\n",
        "val_input_token_index = dict([(char, i) for i, char in enumerate(val_input_characters)])\n",
        "val_target_token_index = dict([(char, i) for i, char in enumerate(val_target_characters)])\n",
        "print(val_input_token_index)\n",
        "print(val_target_token_index)\n",
        "\n",
        "val_encoder_input_data = np.zeros((len(x_val), val_max_encoder_seq_length,val_num_encoder_tokens), dtype=\"float32\")\n",
        "val_decoder_input_data = np.zeros((len(x_val), val_max_decoder_seq_length,val_num_decoder_tokens), dtype=\"float32\")\n",
        "val_decoder_target_data = np.zeros((len(x), max_decoder_seq_length, val_num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(x_val, y_val)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        val_encoder_input_data[i, t ,input_token_index[char]] = 1.0\n",
        "    val_encoder_input_data[i, t + 1 :,input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        val_decoder_input_data[i, t ,target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            val_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    val_decoder_input_data[i, t + 1 :,target_token_index[\" \"]] = 1.0\n",
        "    val_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZU-oUHjZsJH",
        "outputId": "d3a234f5-b80c-4c82-8482-508fee5410c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68215, 30)\n"
          ]
        }
      ],
      "source": [
        "# Using label encoding for the encoder inputs (and then find an embedding using the Embedding layer)\n",
        "encoder_input_data = np.argmax(encoder_input_data, axis=2)\n",
        "val_encoder_input_data = np.argmax(val_encoder_input_data, axis=2)\n",
        "#test_encoder_input_data = np.argmax(test_encoder_input_data, axis=2)\n",
        "print(encoder_input_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSB81yCrbmow"
      },
      "outputs": [],
      "source": [
        "decoder_input_data = np.argmax(decoder_input_data, axis=2)\n",
        "val_decoder_input_data = np.argmax(val_decoder_input_data, axis=2)\n",
        "#test_decoder_input_data = np.argmax(test_decoder_input_array, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "QBnkMEHUciI0"
      },
      "outputs": [],
      "source": [
        "#Build the model\n",
        "def create_model(num_encoder_tokens,embedding_size,cell_type,latent_dimension,dropout,number_of_encoder_layers,num_decoder_tokens,number_of_decoder_layers):\n",
        "\n",
        "  # Define an input sequence and process it.\n",
        "  encoder_inputs = keras.Input(shape=(None,), name='encoder_input')\n",
        "  encoder = None\n",
        "  encoder_outputs = None\n",
        "  state_h = None\n",
        "  state_c = None\n",
        "  en_embed = tf.keras.layers.Embedding(input_dim=num_encoder_tokens, output_dim=embedding_size,\n",
        "                                            name='encoder_embedding')(encoder_inputs)\n",
        "  if cell_type == 'rnn':\n",
        "      encoder = keras.layers.SimpleRNN(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                       name='encoder_hidden_1', dropout=dropout)\n",
        "      encoder_outputs, state_h = encoder(en_embed)\n",
        "  elif cell_type == 'gru':\n",
        "      encoder = keras.layers.GRU(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                  name='encoder_hidden_1', dropout=dropout)\n",
        "      encoder_outputs, state_h = encoder(en_embed)\n",
        "  else:\n",
        "      encoder = keras.layers.LSTM(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                  name='encoder_hidden_1', dropout=dropout)\n",
        "      encoder_outputs, state_h, state_c = encoder(en_embed)\n",
        "\n",
        "  # 1st layer\n",
        "  # number of encoder layers\n",
        "  e_layer = number_of_encoder_layers\n",
        "  for i in range(2, e_layer + 1):\n",
        "    # give the output sequences as input to the next layer also the last state is set as initial state of\n",
        "    # next layer\n",
        "    layer_name = ('encoder_hidden_%d') % i\n",
        "    if cell_type == 'rnn':\n",
        "      encoder = keras.layers.SimpleRNN(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                          name=layer_name, dropout=dropout)\n",
        "      encoder_outputs, state_h = encoder(encoder_outputs, initial_state=[state_h])\n",
        "    elif cell_type == 'gru':\n",
        "        encoder = keras.layers.GRU(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                    name=layer_name, dropout=dropout)\n",
        "        encoder_outputs, state_h = encoder(encoder_outputs, initial_state=[state_h])\n",
        "    else:\n",
        "        encoder = keras.layers.LSTM(latent_dimension, return_state=True, return_sequences=True,\n",
        "                                    name=layer_name, dropout=dropout)\n",
        "        encoder_outputs, state_h, state_c = encoder(encoder_outputs, initial_state=[state_h, state_c])\n",
        "  \n",
        "  encoder_states = None\n",
        "  # save the last state\n",
        "  if cell_type  == 'rnn' or cell_type == 'gru' :\n",
        "      encoder_states = [state_h]\n",
        "  else:\n",
        "      encoder_states = [state_h, state_c]\n",
        "  decoder_inputs = keras.Input(shape=(None,), name='decoder_input')\n",
        "  de_embed = tf.keras.layers.Embedding(num_decoder_tokens, embedding_size, name='decoder_embedding')(decoder_inputs)\n",
        " # number of decoder layers\n",
        "  d_layer = number_of_decoder_layers\n",
        "  decoder = None\n",
        "  # first layer\n",
        "  if cell_type == 'rnn':\n",
        "      decoder = keras.layers.SimpleRNN(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                        name='decoder_hidden_1', dropout=dropout)\n",
        "      # all decoders the initial state is encoder last state of last layer\n",
        "      decoder_outputs, _ = decoder(de_embed, initial_state=encoder_states)\n",
        "  elif cell_type == 'gru':\n",
        "      decoder = keras.layers.GRU(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                  name='decoder_hidden_1', dropout=dropout)\n",
        "      # all decoders the initial state is encoder last state of last layer\n",
        "      decoder_outputs, _ = decoder(de_embed, initial_state=encoder_states)\n",
        "  else:\n",
        "      decoder = keras.layers.LSTM(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                  name='decoder_hidden_1', dropout=dropout)\n",
        "      # all decoders the initial state is encoder last state of last layer\n",
        "      decoder_outputs, _, _ = decoder(de_embed, initial_state=encoder_states)\n",
        "\n",
        "  for i in range(2, d_layer + 1):\n",
        "      layer_name = 'decoder_hidden_%d' % i\n",
        "      if cell_type == 'rnn':\n",
        "          decoder = keras.layers.SimpleRNN(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                            name=layer_name, dropout=dropout)\n",
        "          decoder_outputs, _ = decoder(decoder_outputs, initial_state=encoder_states)\n",
        "      elif cell_type == 'gru':\n",
        "          decoder = keras.layers.GRU(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                      name=layer_name, dropout=dropout)\n",
        "          decoder_outputs, _ = decoder(decoder_outputs, initial_state=encoder_states)\n",
        "      else:\n",
        "          decoder = keras.layers.LSTM(latent_dimension, return_sequences=True, return_state=True,\n",
        "                                      name=layer_name, dropout=dropout)\n",
        "          decoder_outputs, _, _ = decoder(decoder_outputs, initial_state=encoder_states)\n",
        "\n",
        "\n",
        "# Attention layer\n",
        "  attn_out, attn_scores = AttentionLayer(name='attention_1')([encoder_outputs, decoder_outputs])        # Bahdanau Attention\n",
        "  # Concat attention output and decoder output\n",
        "  dense_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer_1')([decoder_outputs, attn_out])\n",
        "\n",
        "  # add a dense layer\n",
        "  decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\", name='decoder_output')\n",
        "  decoder_outputs = decoder_dense(dense_concat_input)\n",
        "\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "  \n",
        "  return model\n",
        "  # # We discard `encoder_outputs` and only keep the states.\n",
        "  # encoder_states = [state_h, state_c]\n",
        "\n",
        "  # # Set up the decoder, using `encoder_states` as initial state.\n",
        "  # decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "  # # We set up our decoder to return full output sequences,\n",
        "  # # and to return internal states as well. We don't use the\n",
        "  # # return states in the training model, but we will use them in inference.\n",
        "  # decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "  # decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "  # decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "  # decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  # # Define the model that will turn\n",
        "  # # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "  # model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sSK2SsA_L5k2"
      },
      "outputs": [],
      "source": [
        "def fit(model,cell_type,encoder_input_data, decoder_input_data, decoder_target_data,batch_size, epochs,number_of_encoder_layers,number_of_decoder_layers,latent_dimension, callbacks=None):\n",
        "  model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
        "  model.fit(\n",
        "      [encoder_input_data, decoder_input_data],\n",
        "      decoder_target_data,\n",
        "      batch_size=batch_size,\n",
        "      epochs=epochs,\n",
        "      callbacks=callbacks\n",
        "  )\n",
        "\n",
        "  # create inference model\n",
        "  encoder_inputs = model.input[0]  # input_1\n",
        "  if cell_type == 'rnn' or cell_type == 'gru':\n",
        "      encoder_outputs, state_h_enc = model.get_layer('encoder_hidden_' + str(number_of_encoder_layers)).output\n",
        "      encoder_states = [state_h_enc]\n",
        "      encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "      decoder_inputs = model.input[1]  # input_2\n",
        "      decoder_outputs = model.get_layer('decoder_embedding')(decoder_inputs)\n",
        "      decoder_states_inputs = []\n",
        "      decoder_states = []\n",
        "\n",
        "      for j in range(1, number_of_decoder_layers + 1):\n",
        "          decoder_state_input_h = keras.Input(shape=(latent_dimension,))\n",
        "          current_states_inputs = [decoder_state_input_h]\n",
        "          decoder = model.get_layer('decoder_hidden_' + str(j))\n",
        "          decoder_outputs, state_h_dec = decoder(decoder_outputs, initial_state=current_states_inputs)\n",
        "          decoder_states += [state_h_dec]\n",
        "          decoder_states_inputs += current_states_inputs\n",
        "  else:\n",
        "      encoder_outputs, state_h_enc, state_c_enc = model.get_layer('encoder_hidden_'+ str(number_of_encoder_layers)).output\n",
        "      encoder_states = [state_h_enc, state_c_enc]\n",
        "      encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "      decoder_inputs = model.input[1]  # input_2\n",
        "      decoder_outputs = model.get_layer('decoder_embedding')(decoder_inputs)\n",
        "      decoder_states_inputs = []\n",
        "      decoder_states = []\n",
        "\n",
        "      for j in range(1,number_of_decoder_layers + 1):\n",
        "          decoder_state_input_h = keras.Input(shape=(latent_dimension,))\n",
        "          decoder_state_input_c = keras.Input(shape=(latent_dimension,))\n",
        "          current_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "          decoder = model.get_layer('decoder_hidden_' + str(j))\n",
        "          decoder_outputs, state_h_dec, state_c_dec = decoder(decoder_outputs, initial_state=current_states_inputs)\n",
        "          decoder_states += [state_h_dec, state_c_dec]\n",
        "          decoder_states_inputs += current_states_inputs\n",
        "          \n",
        "# Attention layer\n",
        "  attn_out, attn_scores = model.get_layer('attention_1')([encoder_outputs, decoder_outputs])        # Bahdanau Attention\n",
        "  # Concat attention input and decoder output\n",
        "  dense_concat_input = keras.layers.Concatenate(axis=-1, name='concat_layer_1')([decoder_outputs, attn_out])\n",
        "\n",
        "  # Softmax FC layer\n",
        "  decoder_dense = model.get_layer('decoder_output')\n",
        "  decoder_outputs = decoder_dense(dense_concat_input)\n",
        "\n",
        "  # Decoder model\n",
        "  decoder_model = keras.Model([encoder_inputs, decoder_inputs] + decoder_states_inputs, [attn_scores, decoder_outputs] + decoder_states)\n",
        "  \n",
        "  # decoder_dense = model.get_layer('decoder_output')\n",
        "  # decoder_outputs = decoder_dense(decoder_outputs)\n",
        "  # decoder_model = keras.Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "  return encoder_model , decoder_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A6tGAC4QQzbY"
      },
      "outputs": [],
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAUk1H6UF2Bw"
      },
      "source": [
        "Creating Custom Attention layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "uqAeIT1_FsBH"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Layer\n",
        "import keras.backend as K\n",
        "\n",
        "class AttentionLayer(Layer):\n",
        "    \"\"\"\n",
        "    This Attention layer class code is used from : https://github.com/thushv89/attention_keras/blob/master/src/layers/attention.py\n",
        "    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n",
        "    There are three sets of weights introduced W_a, U_a, and V_a\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert isinstance(input_shape, list)\n",
        "        # Create a trainable weight variable for this layer.\n",
        "\n",
        "        self.W_a = self.add_weight(name='W_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.U_a = self.add_weight(name='U_a',\n",
        "                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "        self.V_a = self.add_weight(name='V_a',\n",
        "                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n",
        "                                   initializer='uniform',\n",
        "                                   trainable=True)\n",
        "\n",
        "        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n",
        "\n",
        "    def call(self, inputs, verbose=False):\n",
        "        \"\"\"\n",
        "        inputs: [encoder_output_sequence, decoder_output_sequence]\n",
        "        \"\"\"\n",
        "        assert type(inputs) == list\n",
        "        encoder_out_seq, decoder_out_seq = inputs\n",
        "        if verbose:\n",
        "            print('encoder_out_seq>', encoder_out_seq.shape)\n",
        "            print('decoder_out_seq>', decoder_out_seq.shape)\n",
        "\n",
        "        def energy_step(inputs, states):\n",
        "            \"\"\" Step function for computing energy for a single decoder state\n",
        "            inputs: (batchsize * 1 * de_in_dim)\n",
        "            states: (batchsize * 1 * de_latent_dim)\n",
        "            \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            \"\"\" Some parameters required for shaping tensors\"\"\"\n",
        "            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n",
        "            de_hidden = inputs.shape[-1]\n",
        "\n",
        "            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n",
        "            # <= batch size * en_seq_len * latent_dim\n",
        "            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n",
        "\n",
        "            \"\"\" Computing hj.Ua \"\"\"\n",
        "            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n",
        "            if verbose:\n",
        "                print('Ua.h>', U_a_dot_h.shape)\n",
        "\n",
        "            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n",
        "            # <= batch_size*en_seq_len, latent_dim\n",
        "            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n",
        "            if verbose:\n",
        "                print('Ws+Uh>', Ws_plus_Uh.shape)\n",
        "\n",
        "            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n",
        "            # <= batch_size, en_seq_len\n",
        "            e_i = K.softmax(e_i)\n",
        "\n",
        "            if verbose:\n",
        "                print('ei>', e_i.shape)\n",
        "\n",
        "            return e_i, [e_i]\n",
        "\n",
        "        def context_step(inputs, states):\n",
        "            \"\"\" Step function for computing ci using ei \"\"\"\n",
        "\n",
        "            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n",
        "            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n",
        "\n",
        "            # <= batch_size, hidden_size\n",
        "            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n",
        "            if verbose:\n",
        "                print('ci>', c_i.shape)\n",
        "            return c_i, [c_i]\n",
        "\n",
        "        fake_state_c = K.sum(encoder_out_seq, axis=1)\n",
        "        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n",
        "\n",
        "        \"\"\" Computing energy outputs \"\"\"\n",
        "        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n",
        "        last_out, e_outputs, _ = K.rnn(\n",
        "            energy_step, decoder_out_seq, [fake_state_e],\n",
        "        )\n",
        "\n",
        "        \"\"\" Computing context vectors \"\"\"\n",
        "        last_out, c_outputs, _ = K.rnn(\n",
        "            context_step, e_outputs, [fake_state_c],\n",
        "        )\n",
        "\n",
        "        return c_outputs, e_outputs\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        \"\"\" Outputs produced by the layer \"\"\"\n",
        "        return [\n",
        "            # (batch_size, decoder_timesteps, decoder_hid_layer_size)\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n",
        "            # (batch_size, decoder_timesteps, encoder_timesteps)\n",
        "            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n",
        "        ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nV3IKW99gWes"
      },
      "outputs": [],
      "source": [
        "# #Train the model\n",
        "# model = create_model(num_encoder_tokens=num_encoder_tokens,embedding_size=256,cell_type = 'lstm',\n",
        "#                      latent_dimension=latent_dim,\n",
        "#                      dropout=0.2,number_of_encoder_layers = 1,num_decoder_tokens=num_decoder_tokens,\n",
        "#                      number_of_decoder_layers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcddoYuTPa0Z"
      },
      "outputs": [],
      "source": [
        "# from keras.utils.vis_utils import plot_model\n",
        "#   # plot the model\n",
        "# plot_model(model, to_file='model.png', show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fN5-jep3Ssxg"
      },
      "outputs": [],
      "source": [
        "# encoder_model , decoder_model = fit(model=model,cell_type='lstm',encoder_input_data=encoder_input_data, \n",
        "#                                     decoder_input_data=decoder_input_data,\n",
        "#           decoder_target_data=decoder_target_data,batch_size=batch_size,epochs=1,\n",
        "#           number_of_encoder_layers = 1,number_of_decoder_layers=1 ,latent_dimension=latent_dim, \n",
        "#           callbacks=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ZgOEkcFnYEqi"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.font_manager import FontProperties\n",
        "\n",
        "def attention_heatmap(input_word, heatmap_data):\n",
        "\n",
        "    mats = []\n",
        "    dec_inputs = []\n",
        "\n",
        "    for data in heatmap_data:\n",
        "        dec_ind, attn  = data[0], data[1]\n",
        "        mats.append(attn.reshape(-1)[:len(input_word)])\n",
        "        dec_inputs.append(dec_ind)\n",
        "    \n",
        "    attention_mat = np.array(mats)\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    ax.imshow(attention_mat)\n",
        "\n",
        "    ax.set_xticks(np.arange(attention_mat.shape[1]))\n",
        "    ax.set_yticks(np.arange(attention_mat.shape[0]))\n",
        "\n",
        "    ax.set_yticklabels([inp if inp != '\\n' else \"<e>\" for inp in dec_inputs], fontproperties = FontProperties(fname = \"nirmala.ttf\"))\n",
        "    ax.set_xticklabels([char for char in input_word])\n",
        "\n",
        "    ax.tick_params(labelsize = 15)\n",
        "    ax.tick_params(axis = 'x', labelrotation =  45)\n",
        "\n",
        "    return fig\n",
        "\n",
        "# attention_heatmap(None, None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Y1lIdwQZOkKY"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "from IPython.display import display\n",
        "import ast\n",
        "\n",
        "def softmax(x):\n",
        "    denom = sum([np.exp(p) for p in x])\n",
        "    return [np.exp(p) / denom for p in x]\n",
        "\n",
        "def cstr(s, color = 'black'):\n",
        "    return \"<text style=color:#000;padding-top:1.5px;padding-bottom:1.5px;padding-left:2.5px;padding-right:2.5px;background-color:{}>{} </text>\".format(color, s)\n",
        "\n",
        "def get_clr(value, mode):\n",
        "    if(mode == 'l'):\n",
        "        colors = ['#85c2e1', '#89c4e2', '#95cae5', '#99cce6', '#a1d0e8', '#b2d9ec', '#baddee', '#c2e1f0', '#eff7fb', '#f9e8e8', '#f9e8e8', '#f9d4d4', '#f9bdbd', '#f8a8a8', '#f68f8f', '#f47676', '#f45f5f', '#f34343', '#f33b3b', '#f42e2e']\n",
        "        value = int((value * 100) / 5)\n",
        "        return colors[value]\n",
        "    else:\n",
        "        # colors = ['#FFFFFF','#DFFFFF','#BFFFFF','#9FFFFF','#7FFFFF','#5FFFFF','#3FFFFF','#03FFFF','#00EFFF','#00DFFF','#00CFFF','#00BFFF','#00AFFF','#009FFF']\n",
        "        # factor = 0.07142857142857142\n",
        "        # color_index = int(value/factor)\n",
        "        # return colors[color_index]\n",
        "        colors = ['#ffffff', '#ecf7fb', '#daeff7', '#c7e7f3', '#b5dfef', '#a2d7eb', '#90cfe7', '#7dc7e3', '#6abfdf', '#58b7db', '#46afd7']\n",
        "        value = int((value * 100) / 10)\n",
        "        return colors[value]\n",
        "\n",
        "def visualize_c(dec_char, text_colours):\n",
        "    if (dec_char == \"<e>\"):\n",
        "      display(HTML(''.join([cstr(ti, color = ci) for ti, ci in text_colours]) + \" <b> &emsp; &lt; e &gt; </b>  &emsp; &nbsp; \"))\n",
        "    else:\n",
        "      display(HTML(''.join([cstr(ti, color = ci) for ti, ci in text_colours]) + \" <b> &emsp; {}</b>  &emsp; &emsp; \".format(dec_char)))\n",
        "\n",
        "def visualize_l(dec_seq, prob):\n",
        "    text_colours = []\n",
        "\n",
        "    for c, p in zip(dec_seq, prob): \n",
        "        text = (c, get_clr(p, 'l'))\n",
        "        text_colours.append(text)\n",
        "    \n",
        "    display(HTML(''.join([cstr(ti, color = ci) for ti, ci in text_colours])))\n",
        "\n",
        "def visualize_connectivity(N):\n",
        "\n",
        "    # Reading from conv_vis file\n",
        "    with open(\"conn_vis.txt\", \"r\", encoding='utf-8') as filepointer:\n",
        "        \n",
        "        lines = filepointer.readlines()\n",
        "\n",
        "        i = 0\n",
        "        words_visualized = 0\n",
        "\n",
        "        while i < len(lines) and  words_visualized< N:\n",
        "            line = lines[i]\n",
        "            \n",
        "            if line[:4] == \"Next\":\n",
        "                words_visualized += 1\n",
        "                i += 1\n",
        "                continue\n",
        "\n",
        "            if line[:4] != \"Next\": \n",
        "                true_word, dec_char_len = line.split('\\t') \n",
        "                dec_word_len = int(dec_char_len)\n",
        "                i += 1\n",
        "\n",
        "                true_word_array = [c for c in true_word]\n",
        "\n",
        "                for j in range(dec_word_len):\n",
        "                    line = lines[i]\n",
        "                    line = line.split('\\t')\n",
        "  \n",
        "                    dec_char = line[0]\n",
        "                    text_colours = []\n",
        "\n",
        "                    prob = []\n",
        "                    for prob_index in range(1,len(true_word)+1) :\n",
        "                        p = float(line[prob_index])\n",
        "                        prob.append(p)\n",
        "\n",
        "                    line = softmax(prob)\n",
        "\n",
        "                    \n",
        "                    for prob_index in range(len(true_word)) :\n",
        "                        p = float(line[prob_index])\n",
        "\n",
        "                        true_char = true_word_array[prob_index]\n",
        "                        text= (true_char, get_clr(p, 'c') )\n",
        "                        text_colours.append(text)\n",
        "\n",
        "                    visualize_c(dec_char, text_colours)\n",
        "            \n",
        "                    i += 1\n",
        "\n",
        "            print(\"\\n\\n\")\n",
        "\n",
        "def visualize_lstm(N, neuron):\n",
        "\n",
        "    for i in range(N):\n",
        "\n",
        "        file = open(\"lstm_vis_\" + str(i) + \".txt\", \"r\")\n",
        "        input_seq = file.readline()[:-1]\n",
        "        \n",
        "        dec_seq = []\n",
        "        prob = []\n",
        "\n",
        "        for line in file:\n",
        "            temp = line.split('\\t')\n",
        "            dec_seq.append(temp[0])\n",
        "            prob.append(ast.literal_eval(temp[1][:-1])[neuron - 1])\n",
        "\n",
        "        visualize_l(dec_seq, prob)\n",
        "        print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "DSyqWLwoX-fs"
      },
      "outputs": [],
      "source": [
        "from random import sample\n",
        "\n",
        "def infer(model,encoder_test_input_data, test_input_words, test_target_words, num_decoder_characters, max_decoder_seq_length, target_characters_index, inverse_target_characters_index, latent_dim, cell_type, for_test=False):\n",
        "    \n",
        "    #model = keras.models.load_model(\"seq2seq_attention\")\n",
        "\n",
        "    print(model.summary())\n",
        "\n",
        "    # Encoder\n",
        "    encoder_inputs = model.input[0]  # input_1\n",
        "\n",
        "    if cell_type == \"rnn\" or cell_type == \"gru\":\n",
        "        encoder_outputs, state = model.layers[4].output\n",
        "        encoder_model = keras.Model(encoder_inputs, [encoder_outputs] + [state])\n",
        "    \n",
        "    elif cell_type == \"lstm\":\n",
        "        encoder_outputs, state_h_enc, state_c_enc = model.layers[4].output\n",
        "        encoder_model = keras.Model(encoder_inputs, [encoder_outputs] + [state_h_enc, state_c_enc])\n",
        "    \n",
        "    else:\n",
        "        return\n",
        "\n",
        "    decoder_inputs = model.input[1]  # input_2\n",
        "    decoder_outputs = model.layers[3](decoder_inputs)\n",
        "\n",
        "    if cell_type == \"rnn\" or cell_type == \"gru\":\n",
        "        state = keras.Input(shape = (latent_dim, ))\n",
        "        decoder_states_inputs = [state]\n",
        "        decoder_outputs, state = model.layers[5](decoder_outputs, initial_state = decoder_states_inputs)\n",
        "        decoder_states = [state]\n",
        "\n",
        "    elif cell_type == \"lstm\":\n",
        "        state_h_dec, state_c_dec = keras.Input(shape = (latent_dim, )), keras.Input(shape = (latent_dim, ))\n",
        "        decoder_states_inputs = [state_h_dec, state_c_dec]\n",
        "        decoder_outputs, state_h_dec, state_c_dec = model.layers[5](decoder_outputs, initial_state = decoder_states_inputs)\n",
        "        decoder_states = [state_h_dec, state_c_dec]\n",
        "        \n",
        "    attention_inputs = keras.Input(shape = (None, latent_dim, ))\n",
        "    attention_output, attention_scores = model.layers[6]([attention_inputs, decoder_outputs])\n",
        "    decoder_concat_input = model.layers[7]([decoder_outputs, attention_output])\n",
        "\n",
        "    # Dense layer\n",
        "    decoder_dense = model.layers[8]\n",
        "    decoder_outputs = decoder_dense(decoder_concat_input)\n",
        "\n",
        "    # Final decoder model\n",
        "    decoder_model = keras.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs + [attention_inputs], [decoder_outputs] + decoder_states + [attention_scores]\n",
        "    )\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return [1/(1 + np.exp(-z)) for z in x]\n",
        "\n",
        "    def decode_sequence(input_seq):\n",
        "        # Encode the input as state vectors.\n",
        "        encoder_outputs = encoder_model.predict(input_seq)\n",
        "        encoder_output, states_value = encoder_outputs[0], encoder_outputs[1:]\n",
        "        \n",
        "        # Generate empty target sequence of length 1.\n",
        "        target_seq = np.zeros((1, 1))\n",
        "\n",
        "        # Populate the first character of target sequence with the start character.\n",
        "        target_seq[0, 0] = target_characters_index[\"\\t\"]\n",
        "        \n",
        "        stop_condition = False\n",
        "        decoded_sentence = \"\"\n",
        "        heatmap_data = []\n",
        "        visualization_data = []\n",
        "\n",
        "        while not stop_condition:\n",
        "            output = decoder_model.predict([target_seq] + states_value + [encoder_output])\n",
        "            output_tokens, states_value, attention_weights = output[0], output[1:-1], output[-1]\n",
        "\n",
        "            # Sample a token\n",
        "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "            sampled_char = inverse_target_characters_index[sampled_token_index]\n",
        "            decoded_sentence += sampled_char\n",
        "\n",
        "            if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "                stop_condition = True\n",
        "\n",
        "            target_seq = np.zeros((1, 1))\n",
        "            target_seq[0, 0] = sampled_token_index\n",
        "            heatmap_data.append((sampled_char, attention_weights))\n",
        "            visualization_data.append((sampled_char, states_value[0]))\n",
        "\n",
        "        return decoded_sentence, heatmap_data, visualization_data\n",
        "\n",
        "    count, visual_count, test_size = 0, 0, len(test_input_words)\n",
        "\n",
        "    predictions_attention = open(\"predictions_attention.csv\", \"w\", encoding='utf-8')\n",
        "    predictions_attention.write(\"Input Sentence,Predicted Sentence,Original Sentence\\n\")  \n",
        "\n",
        "    visualisation_inputs = sample(range(test_size), 10)\n",
        "    #visualisation_inputs = range(0,2)\n",
        "    heatmaps = []\n",
        "\n",
        "    \n",
        "    for seq_index in range(test_size):\n",
        "        # Take one sequence (part of the training set)\n",
        "        # for trying out decoding.\n",
        "        input_seq = encoder_test_input_data[seq_index : seq_index + 1]\n",
        "        decoded_word, heatmap_data, visualization_data = decode_sequence(input_seq)\n",
        "        orig_word = test_target_words[seq_index][1:]\n",
        "\n",
        "        # print(\"-\")\n",
        "        # print(\"Input sentence:\", test_input_words[seq_index])\n",
        "        # print(\"Decoded sentence:\", decoded_word[:-1])\n",
        "        # print(\"Original sentence:\", orig_word[:-1])\n",
        "\n",
        "        predictions_attention.write(test_input_words[seq_index] + \",\" + decoded_word[:-1] + \",\" + orig_word[:-1] + \"\\n\")\n",
        "\n",
        "        if(orig_word == decoded_word): count += 1\n",
        "        \n",
        "        if for_test:\n",
        "          if seq_index in visualisation_inputs:\n",
        "              \n",
        "              # Heatmap Plot\n",
        "              heatmap = attention_heatmap(test_input_words[seq_index], heatmap_data)\n",
        "              plt.show(heatmap)\n",
        "              heatmaps.append(heatmap)\n",
        "              \n",
        "              # Connectivity Visualization\n",
        "              with open(\"conn_vis.txt\", \"a\", encoding='utf-8') as filepointer:\n",
        "\n",
        "                  '''' The logic to compute the  heatmap and true word '''\n",
        "\n",
        "                  true_word = test_input_words[seq_index]\n",
        "\n",
        "                  ''' Writing data into the conv_vis.txt file for visualisation purpose '''\n",
        "                  \n",
        "                  filepointer.write(true_word)\n",
        "                  filepointer.write(\"\\t\")\n",
        "                  filepointer.write(str(len(heatmap_data)))\n",
        "                  filepointer.write(\"\\n\")\n",
        "\n",
        "                  for tup in range(len(heatmap_data)):\n",
        "                      dec_char = heatmap_data[tup][0]\n",
        "                      dec_char_prob = heatmap_data[tup][1].reshape(-1)\n",
        "                  \n",
        "                      if tup == len(heatmap_data) - 1:\n",
        "                          filepointer.write(\"<e>\")\n",
        "                      else:\n",
        "                          filepointer.write(dec_char)\n",
        "                    \n",
        "                      filepointer.write(\"\\t\")\n",
        "\n",
        "                      for p in range(len(true_word)):\n",
        "                          filepointer.write(str(dec_char_prob[p]))\n",
        "                          filepointer.write(\"\\t\")\n",
        "\n",
        "                      filepointer.write(\"\\n\")\n",
        "\n",
        "                  filepointer.write(\"Next\\n\")\n",
        "\n",
        "\n",
        "              # LSTM Visualization\n",
        "              file = open(\"lstm_vis_\" + str(visual_count) + \".txt\", \"w\", encoding='utf-8')\n",
        "              file.write(test_input_words[seq_index] + \"\\n\")\n",
        "\n",
        "              for i, data in enumerate(visualization_data):\n",
        "          \n",
        "                  dec_char, neuron_activation  = data[0], sigmoid(data[1].reshape(-1))\n",
        "                  \n",
        "                  if i == len(visualization_data) - 1:\n",
        "                      file.write(\"<e>\" + \"\\t\" + str(neuron_activation) + \"\\n\")\n",
        "                  else:\n",
        "                      file.write(dec_char + \"\\t\" + str(neuron_activation) + \"\\n\")\n",
        "\n",
        "              visual_count += 1\n",
        "            \n",
        "    return count / test_size, heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aX7tKRVwYp8O"
      },
      "outputs": [],
      "source": [
        "# val_accuracy, heatmaps = infer(model, val_encoder_input_data, val_input_words, val_target_words, num_decoder_tokens, max_decoder_seq_length, target_token_index, reverse_target_char_index, latent_dim, 'lstm')\n",
        "# print(\"Val Accuracy: \", val_accuracy)\n",
        "\n",
        "# #for i, heatmap in enumerate(heatmaps):\n",
        "# #    wandb.log( {\"heatmap_\" + str(i): heatmap})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZk5FOaYPHyH"
      },
      "outputs": [],
      "source": [
        "# visualize_connectivity(10)\n",
        "# visualize_lstm(10, 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1UTiYLp7XrU0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGj1XpeDiMr9"
      },
      "source": [
        "## Wandb sweep for attention"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "QNjRGbGOiQSq"
      },
      "outputs": [],
      "source": [
        "def main(config = None):\n",
        "    run = wandb.init(config = config)\n",
        "    config = wandb.config\n",
        "\n",
        "    run.name = \"Epochs: \" + str(config.epochs) + \" Embedding Size: \" + str(config.embedding_size) + \" Cell Type: \" + config.cell_type + \" Dropout: \" + str(config.dropout) + \" Encoder Layers: \" + str(config.encoder_layers) + \" Decoder Layers: \" + str(config.decoder_layers) + \" Hidder Layer Size: \" + str(config.hidden_layer_size)\n",
        "\n",
        "    # Configuration\n",
        "    batch_size = 256\n",
        "    epochs = config.epochs\n",
        "    embedding_size = config.embedding_size\n",
        "    latent_dim = config.hidden_layer_size\n",
        "    cell_type = config.cell_type\n",
        "    dropout = config.dropout\n",
        "    \n",
        "   \n",
        "    #Train the model\n",
        "    model = create_model(num_encoder_tokens=num_encoder_tokens,embedding_size=embedding_size,cell_type = cell_type,\n",
        "                     latent_dimension=latent_dim,\n",
        "                     dropout=dropout,number_of_encoder_layers = config.encoder_layers,num_decoder_tokens=num_decoder_tokens,\n",
        "                     number_of_decoder_layers=config.decoder_layers)\n",
        "\n",
        "\n",
        "    encoder_model , decoder_model = fit(model=model,cell_type=config.cell_type,encoder_input_data=encoder_input_data, \n",
        "                                    decoder_input_data=decoder_input_data,\n",
        "          decoder_target_data=decoder_target_data,batch_size=batch_size,epochs=config.epochs,\n",
        "          number_of_encoder_layers = 1,number_of_decoder_layers=1 ,latent_dimension=config.hidden_layer_size, \n",
        "          callbacks=[WandbCallback()])\n",
        "\n",
        "    # Inference for Validation Data\n",
        "    val_accuracy, heatmaps = infer(model, val_encoder_input_data, val_input_words, val_target_words, num_decoder_tokens, max_decoder_seq_length, target_token_index, reverse_target_char_index, latent_dim, cell_type)\n",
        "    wandb.log( {'val_accuracy': val_accuracy})\n",
        "    run.finish()\n",
        "    # Inference for Test Data\n",
        "    # test_accuracy, heatmaps = attention_inference.infer(encoder_test_input_data, test_input_words, test_target_words, num_decoder_characters, max_decoder_seq_length, target_characters_index, inverse_target_characters_index, latent_dim, cell_type)\n",
        "    # wandb.log( { \"test_accuracy\": test_accuracy} )\n",
        "\n",
        "    for i, heatmap in enumerate(heatmaps):\n",
        "        wandb.log( {\"heatmap_\" + str(i): heatmap})\n",
        "    run.finish()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0D4DbPohiUxR"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "  \n",
        "  \"method\": \"bayes\",\n",
        "\n",
        "  'metric': {\n",
        "      'name': 'val_accuracy',\n",
        "      'goal': 'maximize'\n",
        "  },\n",
        "\n",
        "  \"parameters\": {\n",
        "        \"epochs\":{\n",
        "          'values':[20,25]\n",
        "        },\n",
        "        \"embedding_size\": {\n",
        "            \"values\": [32,64, 256]\n",
        "        },\n",
        "        \"encoder_layers\" :{\n",
        "            \"values\" : [1]\n",
        "        },\n",
        "        \"decoder_layers\": {\n",
        "            \"values\": [1]\n",
        "        },\n",
        "        \"hidden_layer_size\": {\n",
        "            \"values\": [64,128,256,512,1024]\n",
        "        },\n",
        "        \"cell_type\": {\n",
        "            \"values\": [\"lstm\", \"gru\",\"rnn\"]\n",
        "        },\n",
        "        \"dropout\": {\n",
        "            \"values\": [0,0.2, 0.3]\n",
        "        },\n",
        "    }\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1c9ea1f56adf432f89f21f594f46a527",
            "219a61e985ec43d497ad912a259ddba4",
            "18aefa16df2d4974b7e529f806650561",
            "a7a886c030624021b4d84e133e2290d7",
            "3f38c236f8cc476fb1266bf83ad718fd",
            "41d00627641e4f27a654c11f91dde817",
            "3208e3bf06444f349b55e6dab4ee6f77",
            "e2b00f8e0c504c09bda814f9b1375959",
            "8644725cdfa04bb4861baed088695de4",
            "c6ff97bb4b064699b5e0c8179b9c27ab",
            "92a3f5aeced8472d8d2d880206cd2aa8",
            "88150d3d06c94fb38d6ed45f2367d30e",
            "7f0248d6cd954a2aac8179b70f724621",
            "62d01b43cecf4fb6a97b78358b97a8ec",
            "23e2baba27144bffa18aa914064d79c2",
            "f92dda85254f406cb87f4ceaeeba56c6",
            "8628284d49b84c99baf17b7e69b11004",
            "aa1ef101b69044789b157de59ea35cf8",
            "9cec9012c841482795ba31d53b4d0b53",
            "7a70aa911811470d9df51c25389f5692",
            "f41145bfbeb24d42b2c15344b7199d16",
            "c9fc68183f4d4b2a915005c6db4b175a",
            "dcaa7f9d48bb43579327c726d6689622",
            "6b66ef4907b4496f9d0aabc774ca4c18",
            "1d3a3726c6f34b108d3d06da1937469a",
            "aa98a80109d745d9aecc98b468e14a36",
            "a2cdff9f9d4e4b65aaee0767d08e0e68",
            "488b6a59ce4944308fa01ea5e53ef51a",
            "df4c74f942084aa59ba4a50b0e59d568",
            "a216d2e70d584f16aa310d53cb1b78e8",
            "f7c80f8569c14ffba23229e1fa69a14a",
            "1795d935b06d47f08f269cecd12b007b",
            "ab19b28682cd4098a467898a2ec9d315",
            "01f9696041f2480b8acfab66e1ce4101",
            "9b06c266558248cfa9f56f145ee3b8f6",
            "190ce0e5018b40ad8c81e27139f9fd03",
            "0c5e4a0a408b44768ddb94ccabdd7421",
            "8a89f67ebc2c4a7096919df0978ea529",
            "0a36b77bf27a458791500e0b82effdf0",
            "468fef44bc50415584357bdfbf69c605",
            "bd80377e237d4ad484f690247286696d",
            "3c49eed8576a46e7bd4da29c68e5397f",
            "e5a57b4eedea4c65bc3faea48a09dd2c",
            "88bcc30646504cafb16fe1bee8042ddb",
            "8c716ed834bc47859cc9a5b995bbd16c",
            "081658dbd3f6402a85ce0fd16ed0e003",
            "c220b4425c3c472ca0b1d8faeb7bd5ea",
            "114ca715b4c849099d1fb90bbe9a2602",
            "ed0616e7fef648afa6c32d6c1ee93dce",
            "425505df75d446c9bf9b88ec11d923e5",
            "e43c55cd7874465f9e0607cdfbc16637",
            "8e253b72680e47e4a5581381f1f3c4c4",
            "46dfcd7d9f0046c5bc1b41dd9c6bc700",
            "9d420c7814c94bf8a841b9177c183657",
            "c3087b49485c4020bcc2e798569698ab",
            "00051e10474c4451bd6a49eaa8570ad6",
            "8d423ab4f83a46afb9a8b41f8985344d",
            "2afc8c0033774e0392106ec082bfea15",
            "e09f7b3851424d18a35f098e2a527931",
            "da86a62d10dd49b7992379e36c575641",
            "4f9b233a45a0439496fc84d3a85423b1",
            "6283d4bebe6d41958fc91906268bcbb3",
            "909fd189136547ef843a1b8747b57eed",
            "40f20c75aa494cbbaa2bc541a3529ba4",
            "2f13788523514d63865262347efcdf45",
            "f1879a21ebf94046abc7cd54fa6cd57d",
            "1322e9884ced40d99f8af68f46a61c24",
            "bc6084fbaa4c46f7be95357660f3f70b",
            "9f6c736d10224763ba1b3ce475545cd9",
            "8085941d0dcf4c848282193d57cf80bd",
            "179ffee7a6dd473e9cc97ffe071080d9",
            "434a7cfab0b742c782065a802abd2294",
            "606f728ee651472c94a8b2d888a3c571",
            "f28c694a86c04491a04102a9ae46e853",
            "16f7b593df734eec9b4d076c67a565e9",
            "3cf743b62ca5461184647623bb1fab02",
            "c415a29c3d8647beb755a4ee2aba8fa4",
            "4103604fa7db424da59214be0b74ff22",
            "667aa2575793404898881c65e3bfac33",
            "cfe07d8be5fe476183fb8d825993fdb6"
          ]
        },
        "id": "sBlfowq9iWYD",
        "outputId": "b64b308d-7a0e-47ba-b98b-6f3ce854c9b3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create sweep with ID: bygbvpb7\n",
            "Sweep URL: https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 23dhww5j with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 1024\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_160040-23dhww5j</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/23dhww5j\" target=\"_blank\">proud-sweep-1</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "267/267 [==============================] - 140s 515ms/step - loss: 1.0340 - accuracy: 0.7318 - _timestamp: 1651766585.0000 - _runtime: 145.0000\n",
            "Epoch 2/25\n",
            "267/267 [==============================] - 138s 515ms/step - loss: 0.4683 - accuracy: 0.8683 - _timestamp: 1651766723.0000 - _runtime: 283.0000\n",
            "Epoch 3/25\n",
            "267/267 [==============================] - 138s 516ms/step - loss: 0.1658 - accuracy: 0.9558 - _timestamp: 1651766861.0000 - _runtime: 421.0000\n",
            "Epoch 4/25\n",
            "267/267 [==============================] - 138s 516ms/step - loss: 0.1137 - accuracy: 0.9694 - _timestamp: 1651766999.0000 - _runtime: 559.0000\n",
            "Epoch 5/25\n",
            "267/267 [==============================] - 137s 515ms/step - loss: 0.0981 - accuracy: 0.9732 - _timestamp: 1651767136.0000 - _runtime: 696.0000\n",
            "Epoch 6/25\n",
            "267/267 [==============================] - 137s 515ms/step - loss: 0.0875 - accuracy: 0.9759 - _timestamp: 1651767274.0000 - _runtime: 834.0000\n",
            "Epoch 7/25\n",
            "267/267 [==============================] - 137s 513ms/step - loss: 0.0799 - accuracy: 0.9777 - _timestamp: 1651767411.0000 - _runtime: 971.0000\n",
            "Epoch 8/25\n",
            "267/267 [==============================] - 137s 514ms/step - loss: 0.0735 - accuracy: 0.9794 - _timestamp: 1651767548.0000 - _runtime: 1108.0000\n",
            "Epoch 9/25\n",
            "267/267 [==============================] - 137s 512ms/step - loss: 0.0683 - accuracy: 0.9809 - _timestamp: 1651767684.0000 - _runtime: 1244.0000\n",
            "Epoch 10/25\n",
            "267/267 [==============================] - 137s 513ms/step - loss: 0.0639 - accuracy: 0.9821 - _timestamp: 1651767821.0000 - _runtime: 1381.0000\n",
            "Epoch 11/25\n",
            "267/267 [==============================] - 137s 512ms/step - loss: 0.0602 - accuracy: 0.9831 - _timestamp: 1651767958.0000 - _runtime: 1518.0000\n",
            "Epoch 12/25\n",
            "267/267 [==============================] - 137s 512ms/step - loss: 0.0573 - accuracy: 0.9838 - _timestamp: 1651768095.0000 - _runtime: 1655.0000\n",
            "Epoch 13/25\n",
            "267/267 [==============================] - 137s 511ms/step - loss: 0.0541 - accuracy: 0.9846 - _timestamp: 1651768231.0000 - _runtime: 1791.0000\n",
            "Epoch 14/25\n",
            "267/267 [==============================] - 136s 511ms/step - loss: 0.0516 - accuracy: 0.9853 - _timestamp: 1651768368.0000 - _runtime: 1928.0000\n",
            "Epoch 15/25\n",
            "267/267 [==============================] - 136s 510ms/step - loss: 0.0488 - accuracy: 0.9860 - _timestamp: 1651768504.0000 - _runtime: 2064.0000\n",
            "Epoch 16/25\n",
            "267/267 [==============================] - 136s 510ms/step - loss: 0.0471 - accuracy: 0.9865 - _timestamp: 1651768640.0000 - _runtime: 2200.0000\n",
            "Epoch 17/25\n",
            "267/267 [==============================] - 136s 510ms/step - loss: 0.0448 - accuracy: 0.9872 - _timestamp: 1651768776.0000 - _runtime: 2336.0000\n",
            "Epoch 18/25\n",
            "267/267 [==============================] - 136s 509ms/step - loss: 0.0435 - accuracy: 0.9875 - _timestamp: 1651768912.0000 - _runtime: 2472.0000\n",
            "Epoch 19/25\n",
            "267/267 [==============================] - 136s 508ms/step - loss: 0.0411 - accuracy: 0.9881 - _timestamp: 1651769048.0000 - _runtime: 2608.0000\n",
            "Epoch 20/25\n",
            "267/267 [==============================] - 135s 507ms/step - loss: 0.0398 - accuracy: 0.9886 - _timestamp: 1651769183.0000 - _runtime: 2743.0000\n",
            "Epoch 21/25\n",
            "267/267 [==============================] - 135s 508ms/step - loss: 0.0387 - accuracy: 0.9888 - _timestamp: 1651769319.0000 - _runtime: 2879.0000\n",
            "Epoch 22/25\n",
            "267/267 [==============================] - 135s 507ms/step - loss: 0.0373 - accuracy: 0.9892 - _timestamp: 1651769454.0000 - _runtime: 3014.0000\n",
            "Epoch 23/25\n",
            "267/267 [==============================] - 136s 508ms/step - loss: 0.0364 - accuracy: 0.9894 - _timestamp: 1651769590.0000 - _runtime: 3150.0000\n",
            "Epoch 24/25\n",
            "267/267 [==============================] - 135s 506ms/step - loss: 0.0348 - accuracy: 0.9898 - _timestamp: 1651769725.0000 - _runtime: 3285.0000\n",
            "Epoch 25/25\n",
            "267/267 [==============================] - 135s 506ms/step - loss: 0.0336 - accuracy: 0.9902 - _timestamp: 1651769860.0000 - _runtime: 3420.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 256)    6912        ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 256)    12544       ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (SimpleRNN)   [(None, None, 1024)  1311744     ['encoder_embedding[0][0]']      \n",
            "                                , (None, 1024)]                                                   \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (SimpleRNN)   [(None, None, 1024)  1311744     ['decoder_embedding[0][0]',      \n",
            "                                , (None, 1024)]                   'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 1024)  2098176     ['encoder_hidden_1[0][0]',       \n",
            "                                , (None, None, None               'decoder_hidden_1[0][0]']       \n",
            "                                ))                                                                \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 2048)   0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     100401      ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,841,521\n",
            "Trainable params: 4,841,521\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c9ea1f56adf432f89f21f594f46a527",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▅▇▇█████████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▄▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99023</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.03356</td></tr><tr><td>val_accuracy</td><td>0.5676</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">proud-sweep-1</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/23dhww5j\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/23dhww5j</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_160040-23dhww5j/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 64s5io18 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_174726-64s5io18</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/64s5io18\" target=\"_blank\">lunar-sweep-7</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "267/267 [==============================] - 27s 88ms/step - loss: 1.0893 - accuracy: 0.7177 - _timestamp: 1651772878.0000 - _runtime: 32.0000\n",
            "Epoch 2/25\n",
            "267/267 [==============================] - 24s 89ms/step - loss: 0.7108 - accuracy: 0.7913 - _timestamp: 1651772902.0000 - _runtime: 56.0000\n",
            "Epoch 3/25\n",
            "267/267 [==============================] - 23s 88ms/step - loss: 0.3888 - accuracy: 0.8895 - _timestamp: 1651772925.0000 - _runtime: 79.0000\n",
            "Epoch 4/25\n",
            "267/267 [==============================] - 23s 88ms/step - loss: 0.1781 - accuracy: 0.9511 - _timestamp: 1651772948.0000 - _runtime: 102.0000\n",
            "Epoch 5/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.1406 - accuracy: 0.9613 - _timestamp: 1651772972.0000 - _runtime: 126.0000\n",
            "Epoch 6/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.1235 - accuracy: 0.9661 - _timestamp: 1651772996.0000 - _runtime: 150.0000\n",
            "Epoch 7/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.1119 - accuracy: 0.9693 - _timestamp: 1651773019.0000 - _runtime: 173.0000\n",
            "Epoch 8/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.1024 - accuracy: 0.9718 - _timestamp: 1651773043.0000 - _runtime: 197.0000\n",
            "Epoch 9/25\n",
            "267/267 [==============================] - 24s 89ms/step - loss: 0.0949 - accuracy: 0.9737 - _timestamp: 1651773067.0000 - _runtime: 221.0000\n",
            "Epoch 10/25\n",
            "267/267 [==============================] - 24s 89ms/step - loss: 0.0890 - accuracy: 0.9754 - _timestamp: 1651773090.0000 - _runtime: 244.0000\n",
            "Epoch 11/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.0835 - accuracy: 0.9767 - _timestamp: 1651773114.0000 - _runtime: 268.0000\n",
            "Epoch 12/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.0782 - accuracy: 0.9781 - _timestamp: 1651773137.0000 - _runtime: 291.0000\n",
            "Epoch 13/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.0732 - accuracy: 0.9794 - _timestamp: 1651773161.0000 - _runtime: 315.0000\n",
            "Epoch 14/25\n",
            "267/267 [==============================] - 23s 88ms/step - loss: 0.0690 - accuracy: 0.9805 - _timestamp: 1651773184.0000 - _runtime: 338.0000\n",
            "Epoch 15/25\n",
            "267/267 [==============================] - 23s 88ms/step - loss: 0.0646 - accuracy: 0.9818 - _timestamp: 1651773208.0000 - _runtime: 362.0000\n",
            "Epoch 16/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.0610 - accuracy: 0.9827 - _timestamp: 1651773231.0000 - _runtime: 385.0000\n",
            "Epoch 17/25\n",
            "267/267 [==============================] - 23s 88ms/step - loss: 0.0571 - accuracy: 0.9837 - _timestamp: 1651773255.0000 - _runtime: 409.0000\n",
            "Epoch 18/25\n",
            "267/267 [==============================] - 23s 88ms/step - loss: 0.0538 - accuracy: 0.9848 - _timestamp: 1651773278.0000 - _runtime: 432.0000\n",
            "Epoch 19/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.0501 - accuracy: 0.9857 - _timestamp: 1651773302.0000 - _runtime: 456.0000\n",
            "Epoch 20/25\n",
            "267/267 [==============================] - 24s 89ms/step - loss: 0.0472 - accuracy: 0.9866 - _timestamp: 1651773325.0000 - _runtime: 479.0000\n",
            "Epoch 21/25\n",
            "267/267 [==============================] - 24s 90ms/step - loss: 0.0442 - accuracy: 0.9874 - _timestamp: 1651773349.0000 - _runtime: 503.0000\n",
            "Epoch 22/25\n",
            "267/267 [==============================] - 24s 90ms/step - loss: 0.0413 - accuracy: 0.9882 - _timestamp: 1651773373.0000 - _runtime: 527.0000\n",
            "Epoch 23/25\n",
            "267/267 [==============================] - 24s 89ms/step - loss: 0.0388 - accuracy: 0.9888 - _timestamp: 1651773397.0000 - _runtime: 551.0000\n",
            "Epoch 24/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.0361 - accuracy: 0.9896 - _timestamp: 1651773421.0000 - _runtime: 575.0000\n",
            "Epoch 25/25\n",
            "267/267 [==============================] - 24s 88ms/step - loss: 0.0339 - accuracy: 0.9903 - _timestamp: 1651773444.0000 - _runtime: 598.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 64)     1728        ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 64)     3136        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (GRU)         [(None, None, 256),  247296      ['encoder_embedding[0][0]']      \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (GRU)         [(None, None, 256),  247296      ['decoder_embedding[0][0]',      \n",
            "                                 (None, 256)]                     'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 256),  131328      ['encoder_hidden_1[0][0]',       \n",
            "                                 (None, None, None)               'decoder_hidden_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 512)    0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     25137       ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 655,921\n",
            "Trainable params: 655,921\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8644725cdfa04bb4861baed088695de4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▇▇▇▇██████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99029</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.03386</td></tr><tr><td>val_accuracy</td><td>0.58049</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">lunar-sweep-7</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/64s5io18\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/64s5io18</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_174726-64s5io18/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: b7rjoxut with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_184707-b7rjoxut</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/b7rjoxut\" target=\"_blank\">faithful-sweep-12</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "267/267 [==============================] - 55s 197ms/step - loss: 1.1308 - accuracy: 0.7056 - _timestamp: 1651776491.0000 - _runtime: 64.0000\n",
            "Epoch 2/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.7848 - accuracy: 0.7736 - _timestamp: 1651776543.0000 - _runtime: 116.0000\n",
            "Epoch 3/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.6882 - accuracy: 0.8074 - _timestamp: 1651776595.0000 - _runtime: 168.0000\n",
            "Epoch 4/25\n",
            "267/267 [==============================] - 52s 194ms/step - loss: 0.4496 - accuracy: 0.8707 - _timestamp: 1651776647.0000 - _runtime: 220.0000\n",
            "Epoch 5/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.2075 - accuracy: 0.9438 - _timestamp: 1651776699.0000 - _runtime: 272.0000\n",
            "Epoch 6/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.1555 - accuracy: 0.9590 - _timestamp: 1651776751.0000 - _runtime: 324.0000\n",
            "Epoch 7/25\n",
            "267/267 [==============================] - 53s 199ms/step - loss: 0.1331 - accuracy: 0.9647 - _timestamp: 1651776805.0000 - _runtime: 378.0000\n",
            "Epoch 8/25\n",
            "267/267 [==============================] - 53s 200ms/step - loss: 0.1194 - accuracy: 0.9681 - _timestamp: 1651776858.0000 - _runtime: 431.0000\n",
            "Epoch 9/25\n",
            "267/267 [==============================] - 53s 198ms/step - loss: 0.1097 - accuracy: 0.9705 - _timestamp: 1651776911.0000 - _runtime: 484.0000\n",
            "Epoch 10/25\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.1024 - accuracy: 0.9723 - _timestamp: 1651776963.0000 - _runtime: 536.0000\n",
            "Epoch 11/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0962 - accuracy: 0.9738 - _timestamp: 1651777015.0000 - _runtime: 588.0000\n",
            "Epoch 12/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0904 - accuracy: 0.9752 - _timestamp: 1651777068.0000 - _runtime: 641.0000\n",
            "Epoch 13/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0860 - accuracy: 0.9763 - _timestamp: 1651777120.0000 - _runtime: 693.0000\n",
            "Epoch 14/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0821 - accuracy: 0.9774 - _timestamp: 1651777172.0000 - _runtime: 745.0000\n",
            "Epoch 15/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0775 - accuracy: 0.9785 - _timestamp: 1651777224.0000 - _runtime: 797.0000\n",
            "Epoch 16/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0744 - accuracy: 0.9795 - _timestamp: 1651777276.0000 - _runtime: 849.0000\n",
            "Epoch 17/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0709 - accuracy: 0.9801 - _timestamp: 1651777328.0000 - _runtime: 901.0000\n",
            "Epoch 18/25\n",
            "267/267 [==============================] - 52s 194ms/step - loss: 0.0686 - accuracy: 0.9808 - _timestamp: 1651777380.0000 - _runtime: 953.0000\n",
            "Epoch 19/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0656 - accuracy: 0.9815 - _timestamp: 1651777432.0000 - _runtime: 1005.0000\n",
            "Epoch 20/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0634 - accuracy: 0.9821 - _timestamp: 1651777484.0000 - _runtime: 1057.0000\n",
            "Epoch 21/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0610 - accuracy: 0.9827 - _timestamp: 1651777536.0000 - _runtime: 1109.0000\n",
            "Epoch 22/25\n",
            "267/267 [==============================] - 52s 194ms/step - loss: 0.0593 - accuracy: 0.9833 - _timestamp: 1651777588.0000 - _runtime: 1161.0000\n",
            "Epoch 23/25\n",
            "267/267 [==============================] - 52s 194ms/step - loss: 0.0570 - accuracy: 0.9838 - _timestamp: 1651777639.0000 - _runtime: 1212.0000\n",
            "Epoch 24/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0553 - accuracy: 0.9842 - _timestamp: 1651777691.0000 - _runtime: 1264.0000\n",
            "Epoch 25/25\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0534 - accuracy: 0.9847 - _timestamp: 1651777744.0000 - _runtime: 1317.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 32)     864         ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 32)     1568        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (SimpleRNN)   [(None, None, 512),  279040      ['encoder_embedding[0][0]']      \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (SimpleRNN)   [(None, None, 512),  279040      ['decoder_embedding[0][0]',      \n",
            "                                 (None, 512)]                     'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 512),  524800      ['encoder_hidden_1[0][0]',       \n",
            "                                 (None, None, None)               'decoder_hidden_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 1024)   0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     50225       ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,135,537\n",
            "Trainable params: 1,135,537\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8628284d49b84c99baf17b7e69b11004",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▇▇▇██████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.98475</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.05338</td></tr><tr><td>val_accuracy</td><td>0.5802</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">faithful-sweep-12</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/b7rjoxut\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/b7rjoxut</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_184707-b7rjoxut/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4e7wg283 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 1024\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_195905-4e7wg283</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/4e7wg283\" target=\"_blank\">avid-sweep-16</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "267/267 [==============================] - 140s 511ms/step - loss: 1.2772 - accuracy: 0.6802 - _timestamp: 1651780894.0000 - _runtime: 149.0000\n",
            "Epoch 2/25\n",
            "267/267 [==============================] - 135s 507ms/step - loss: 0.8601 - accuracy: 0.7545 - _timestamp: 1651781029.0000 - _runtime: 284.0000\n",
            "Epoch 3/25\n",
            "267/267 [==============================] - 136s 508ms/step - loss: 0.7394 - accuracy: 0.7847 - _timestamp: 1651781165.0000 - _runtime: 420.0000\n",
            "Epoch 4/25\n",
            "267/267 [==============================] - 135s 506ms/step - loss: 0.6619 - accuracy: 0.8084 - _timestamp: 1651781300.0000 - _runtime: 555.0000\n",
            "Epoch 5/25\n",
            "267/267 [==============================] - 135s 506ms/step - loss: 0.4997 - accuracy: 0.8573 - _timestamp: 1651781435.0000 - _runtime: 690.0000\n",
            "Epoch 6/25\n",
            "267/267 [==============================] - 134s 503ms/step - loss: 0.5085 - accuracy: 0.8577 - _timestamp: 1651781569.0000 - _runtime: 824.0000\n",
            "Epoch 7/25\n",
            "267/267 [==============================] - 134s 503ms/step - loss: 0.6490 - accuracy: 0.8109 - _timestamp: 1651781703.0000 - _runtime: 958.0000\n",
            "Epoch 8/25\n",
            "267/267 [==============================] - 134s 501ms/step - loss: 0.6244 - accuracy: 0.8190 - _timestamp: 1651781837.0000 - _runtime: 1092.0000\n",
            "Epoch 9/25\n",
            "267/267 [==============================] - 133s 499ms/step - loss: 0.6027 - accuracy: 0.8247 - _timestamp: 1651781970.0000 - _runtime: 1225.0000\n",
            "Epoch 10/25\n",
            "267/267 [==============================] - 133s 499ms/step - loss: 0.5623 - accuracy: 0.8350 - _timestamp: 1651782104.0000 - _runtime: 1359.0000\n",
            "Epoch 11/25\n",
            "267/267 [==============================] - 133s 500ms/step - loss: 0.5280 - accuracy: 0.8438 - _timestamp: 1651782237.0000 - _runtime: 1492.0000\n",
            "Epoch 12/25\n",
            "267/267 [==============================] - 134s 500ms/step - loss: 0.4993 - accuracy: 0.8519 - _timestamp: 1651782371.0000 - _runtime: 1626.0000\n",
            "Epoch 13/25\n",
            "267/267 [==============================] - 133s 499ms/step - loss: 0.5095 - accuracy: 0.8492 - _timestamp: 1651782504.0000 - _runtime: 1759.0000\n",
            "Epoch 14/25\n",
            "267/267 [==============================] - 133s 499ms/step - loss: 0.4898 - accuracy: 0.8533 - _timestamp: 1651782637.0000 - _runtime: 1892.0000\n",
            "Epoch 15/25\n",
            "267/267 [==============================] - 133s 499ms/step - loss: 0.4754 - accuracy: 0.8572 - _timestamp: 1651782770.0000 - _runtime: 2025.0000\n",
            "Epoch 16/25\n",
            "267/267 [==============================] - 133s 498ms/step - loss: 0.4691 - accuracy: 0.8589 - _timestamp: 1651782903.0000 - _runtime: 2158.0000\n",
            "Epoch 17/25\n",
            "267/267 [==============================] - 133s 498ms/step - loss: 0.4589 - accuracy: 0.8621 - _timestamp: 1651783036.0000 - _runtime: 2291.0000\n",
            "Epoch 18/25\n",
            "267/267 [==============================] - 133s 497ms/step - loss: 0.4347 - accuracy: 0.8685 - _timestamp: 1651783169.0000 - _runtime: 2424.0000\n",
            "Epoch 19/25\n",
            "267/267 [==============================] - 133s 497ms/step - loss: 0.4249 - accuracy: 0.8715 - _timestamp: 1651783302.0000 - _runtime: 2557.0000\n",
            "Epoch 20/25\n",
            "267/267 [==============================] - 133s 497ms/step - loss: 0.4253 - accuracy: 0.8710 - _timestamp: 1651783434.0000 - _runtime: 2689.0000\n",
            "Epoch 21/25\n",
            "267/267 [==============================] - 132s 496ms/step - loss: 0.3933 - accuracy: 0.8806 - _timestamp: 1651783567.0000 - _runtime: 2822.0000\n",
            "Epoch 22/25\n",
            "267/267 [==============================] - 132s 495ms/step - loss: 0.4526 - accuracy: 0.8639 - _timestamp: 1651783699.0000 - _runtime: 2954.0000\n",
            "Epoch 23/25\n",
            "267/267 [==============================] - 132s 493ms/step - loss: 0.4120 - accuracy: 0.8747 - _timestamp: 1651783831.0000 - _runtime: 3086.0000\n",
            "Epoch 24/25\n",
            "267/267 [==============================] - 131s 492ms/step - loss: 0.3786 - accuracy: 0.8848 - _timestamp: 1651783962.0000 - _runtime: 3217.0000\n",
            "Epoch 25/25\n",
            "267/267 [==============================] - 131s 492ms/step - loss: 0.3452 - accuracy: 0.8949 - _timestamp: 1651784093.0000 - _runtime: 3348.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 32)     864         ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 32)     1568        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (SimpleRNN)   [(None, None, 1024)  1082368     ['encoder_embedding[0][0]']      \n",
            "                                , (None, 1024)]                                                   \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (SimpleRNN)   [(None, None, 1024)  1082368     ['decoder_embedding[0][0]',      \n",
            "                                , (None, 1024)]                   'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 1024)  2098176     ['encoder_hidden_1[0][0]',       \n",
            "                                , (None, None, None               'decoder_hidden_1[0][0]']       \n",
            "                                ))                                                                \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 2048)   0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     100401      ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4,365,745\n",
            "Trainable params: 4,365,745\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1d3a3726c6f34b108d3d06da1937469a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▅▇▇▅▆▆▆▆▇▇▇▇▇▇▇▇▇█▇▇██</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▅▄▃▂▂▃▃▃▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.89488</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.34517</td></tr><tr><td>val_accuracy</td><td>0.00161</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">avid-sweep-16</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/4e7wg283\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/4e7wg283</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_195905-4e7wg283/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n3jimzt2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_214758-n3jimzt2</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/n3jimzt2\" target=\"_blank\">colorful-sweep-23</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "267/267 [==============================] - 53s 184ms/step - loss: 1.0960 - accuracy: 0.7120 - _timestamp: 1651787340.0000 - _runtime: 62.0000\n",
            "Epoch 2/25\n",
            "267/267 [==============================] - 49s 182ms/step - loss: 0.7616 - accuracy: 0.7749 - _timestamp: 1651787389.0000 - _runtime: 111.0000\n",
            "Epoch 3/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.4939 - accuracy: 0.8579 - _timestamp: 1651787438.0000 - _runtime: 160.0000\n",
            "Epoch 4/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.2019 - accuracy: 0.9454 - _timestamp: 1651787486.0000 - _runtime: 208.0000\n",
            "Epoch 5/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.1469 - accuracy: 0.9607 - _timestamp: 1651787535.0000 - _runtime: 257.0000\n",
            "Epoch 6/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.1249 - accuracy: 0.9665 - _timestamp: 1651787584.0000 - _runtime: 306.0000\n",
            "Epoch 7/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.1109 - accuracy: 0.9701 - _timestamp: 1651787633.0000 - _runtime: 355.0000\n",
            "Epoch 8/25\n",
            "267/267 [==============================] - 49s 182ms/step - loss: 0.1003 - accuracy: 0.9728 - _timestamp: 1651787681.0000 - _runtime: 403.0000\n",
            "Epoch 9/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0913 - accuracy: 0.9750 - _timestamp: 1651787730.0000 - _runtime: 452.0000\n",
            "Epoch 10/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0829 - accuracy: 0.9771 - _timestamp: 1651787779.0000 - _runtime: 501.0000\n",
            "Epoch 11/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0758 - accuracy: 0.9790 - _timestamp: 1651787828.0000 - _runtime: 550.0000\n",
            "Epoch 12/25\n",
            "267/267 [==============================] - 49s 182ms/step - loss: 0.0694 - accuracy: 0.9806 - _timestamp: 1651787876.0000 - _runtime: 598.0000\n",
            "Epoch 13/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0634 - accuracy: 0.9822 - _timestamp: 1651787925.0000 - _runtime: 647.0000\n",
            "Epoch 14/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0579 - accuracy: 0.9837 - _timestamp: 1651787974.0000 - _runtime: 696.0000\n",
            "Epoch 15/25\n",
            "267/267 [==============================] - 49s 182ms/step - loss: 0.0524 - accuracy: 0.9852 - _timestamp: 1651788023.0000 - _runtime: 745.0000\n",
            "Epoch 16/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0479 - accuracy: 0.9864 - _timestamp: 1651788071.0000 - _runtime: 793.0000\n",
            "Epoch 17/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0437 - accuracy: 0.9876 - _timestamp: 1651788120.0000 - _runtime: 842.0000\n",
            "Epoch 18/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0395 - accuracy: 0.9887 - _timestamp: 1651788169.0000 - _runtime: 891.0000\n",
            "Epoch 19/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0358 - accuracy: 0.9897 - _timestamp: 1651788218.0000 - _runtime: 940.0000\n",
            "Epoch 20/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0327 - accuracy: 0.9905 - _timestamp: 1651788266.0000 - _runtime: 988.0000\n",
            "Epoch 21/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0293 - accuracy: 0.9915 - _timestamp: 1651788315.0000 - _runtime: 1037.0000\n",
            "Epoch 22/25\n",
            "267/267 [==============================] - 49s 182ms/step - loss: 0.0263 - accuracy: 0.9923 - _timestamp: 1651788364.0000 - _runtime: 1086.0000\n",
            "Epoch 23/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0241 - accuracy: 0.9929 - _timestamp: 1651788413.0000 - _runtime: 1135.0000\n",
            "Epoch 24/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0221 - accuracy: 0.9934 - _timestamp: 1651788461.0000 - _runtime: 1183.0000\n",
            "Epoch 25/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0203 - accuracy: 0.9940 - _timestamp: 1651788510.0000 - _runtime: 1232.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 32)     864         ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 32)     1568        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (GRU)         [(None, None, 512),  838656      ['encoder_embedding[0][0]']      \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (GRU)         [(None, None, 512),  838656      ['decoder_embedding[0][0]',      \n",
            "                                 (None, 512)]                     'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 512),  524800      ['encoder_hidden_1[0][0]',       \n",
            "                                 (None, None, None)               'decoder_hidden_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 1024)   0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     50225       ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,254,769\n",
            "Trainable params: 2,254,769\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ab19b28682cd4098a467898a2ec9d315",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▇▇▇▇▇█████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▄▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.994</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.02026</td></tr><tr><td>val_accuracy</td><td>0.57434</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">colorful-sweep-23</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/n3jimzt2\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/n3jimzt2</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_214758-n3jimzt2/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: vvfrckts with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 1024\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220505_225752-vvfrckts</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/vvfrckts\" target=\"_blank\">warm-sweep-25</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "  6/267 [..............................] - ETA: 2:27 - loss: 2.9202 - accuracy: 0.5445WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.2208s vs `on_train_batch_end` time: 0.3290s). Check your callbacks.\n",
            "267/267 [==============================] - 155s 566ms/step - loss: 1.0761 - accuracy: 0.7139 - _timestamp: 1651791637.0000 - _runtime: 165.0000\n",
            "Epoch 2/25\n",
            "267/267 [==============================] - 151s 565ms/step - loss: 0.7545 - accuracy: 0.7748 - _timestamp: 1651791788.0000 - _runtime: 316.0000\n",
            "Epoch 3/25\n",
            "267/267 [==============================] - 151s 565ms/step - loss: 0.6197 - accuracy: 0.8147 - _timestamp: 1651791938.0000 - _runtime: 466.0000\n",
            "Epoch 4/25\n",
            "267/267 [==============================] - 151s 565ms/step - loss: 0.4627 - accuracy: 0.8612 - _timestamp: 1651792089.0000 - _runtime: 617.0000\n",
            "Epoch 5/25\n",
            "267/267 [==============================] - 151s 564ms/step - loss: 0.3307 - accuracy: 0.9010 - _timestamp: 1651792240.0000 - _runtime: 768.0000\n",
            "Epoch 6/25\n",
            "267/267 [==============================] - 151s 564ms/step - loss: 0.2373 - accuracy: 0.9299 - _timestamp: 1651792390.0000 - _runtime: 918.0000\n",
            "Epoch 7/25\n",
            "267/267 [==============================] - 151s 564ms/step - loss: 0.1737 - accuracy: 0.9492 - _timestamp: 1651792541.0000 - _runtime: 1069.0000\n",
            "Epoch 8/25\n",
            "267/267 [==============================] - 151s 564ms/step - loss: 0.1285 - accuracy: 0.9629 - _timestamp: 1651792692.0000 - _runtime: 1220.0000\n",
            "Epoch 9/25\n",
            "267/267 [==============================] - 151s 564ms/step - loss: 0.0965 - accuracy: 0.9724 - _timestamp: 1651792842.0000 - _runtime: 1370.0000\n",
            "Epoch 10/25\n",
            "267/267 [==============================] - 150s 564ms/step - loss: 0.0725 - accuracy: 0.9793 - _timestamp: 1651792993.0000 - _runtime: 1521.0000\n",
            "Epoch 11/25\n",
            "267/267 [==============================] - 150s 564ms/step - loss: 0.0559 - accuracy: 0.9839 - _timestamp: 1651793143.0000 - _runtime: 1671.0000\n",
            "Epoch 12/25\n",
            "267/267 [==============================] - 150s 564ms/step - loss: 0.0430 - accuracy: 0.9876 - _timestamp: 1651793294.0000 - _runtime: 1822.0000\n",
            "Epoch 13/25\n",
            "267/267 [==============================] - 151s 564ms/step - loss: 0.0344 - accuracy: 0.9901 - _timestamp: 1651793444.0000 - _runtime: 1972.0000\n",
            "Epoch 14/25\n",
            "267/267 [==============================] - 150s 564ms/step - loss: 0.0278 - accuracy: 0.9919 - _timestamp: 1651793595.0000 - _runtime: 2123.0000\n",
            "Epoch 15/25\n",
            "267/267 [==============================] - 150s 564ms/step - loss: 0.0234 - accuracy: 0.9931 - _timestamp: 1651793745.0000 - _runtime: 2273.0000\n",
            "Epoch 16/25\n",
            "267/267 [==============================] - 150s 563ms/step - loss: 0.0200 - accuracy: 0.9941 - _timestamp: 1651793896.0000 - _runtime: 2424.0000\n",
            "Epoch 17/25\n",
            "267/267 [==============================] - 151s 564ms/step - loss: 0.0178 - accuracy: 0.9947 - _timestamp: 1651794046.0000 - _runtime: 2574.0000\n",
            "Epoch 18/25\n",
            "267/267 [==============================] - 150s 564ms/step - loss: 0.0160 - accuracy: 0.9953 - _timestamp: 1651794197.0000 - _runtime: 2725.0000\n",
            "Epoch 19/25\n",
            "267/267 [==============================] - 150s 563ms/step - loss: 0.0150 - accuracy: 0.9956 - _timestamp: 1651794347.0000 - _runtime: 2875.0000\n",
            "Epoch 20/25\n",
            "267/267 [==============================] - 150s 563ms/step - loss: 0.0140 - accuracy: 0.9958 - _timestamp: 1651794498.0000 - _runtime: 3026.0000\n",
            "Epoch 21/25\n",
            "267/267 [==============================] - 150s 563ms/step - loss: 0.0128 - accuracy: 0.9962 - _timestamp: 1651794648.0000 - _runtime: 3176.0000\n",
            "Epoch 22/25\n",
            "267/267 [==============================] - 150s 563ms/step - loss: 0.0123 - accuracy: 0.9964 - _timestamp: 1651794798.0000 - _runtime: 3326.0000\n",
            "Epoch 23/25\n",
            "267/267 [==============================] - 151s 564ms/step - loss: 0.0118 - accuracy: 0.9965 - _timestamp: 1651794949.0000 - _runtime: 3477.0000\n",
            "Epoch 24/25\n",
            "267/267 [==============================] - 150s 564ms/step - loss: 0.0114 - accuracy: 0.9966 - _timestamp: 1651795099.0000 - _runtime: 3627.0000\n",
            "Epoch 25/25\n",
            "267/267 [==============================] - 150s 563ms/step - loss: 0.0111 - accuracy: 0.9967 - _timestamp: 1651795250.0000 - _runtime: 3778.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 32)     864         ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 32)     1568        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (LSTM)        [(None, None, 1024)  4329472     ['encoder_embedding[0][0]']      \n",
            "                                , (None, 1024),                                                   \n",
            "                                 (None, 1024)]                                                    \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (LSTM)        [(None, None, 1024)  4329472     ['decoder_embedding[0][0]',      \n",
            "                                , (None, 1024),                   'encoder_hidden_1[0][1]',       \n",
            "                                 (None, 1024)]                    'encoder_hidden_1[0][2]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 1024)  2098176     ['encoder_hidden_1[0][0]',       \n",
            "                                , (None, None, None               'decoder_hidden_1[0][0]']       \n",
            "                                ))                                                                \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 2048)   0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     100401      ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,859,953\n",
            "Trainable params: 10,859,953\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd80377e237d4ad484f690247286696d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▃▅▆▆▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99673</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.01112</td></tr><tr><td>val_accuracy</td><td>0.36575</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">warm-sweep-25</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/vvfrckts\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/vvfrckts</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220505_225752-vvfrckts/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: n6urd5er with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: rnn\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220506_005655-n6urd5er</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/n6urd5er\" target=\"_blank\">sandy-sweep-27</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "267/267 [==============================] - 56s 198ms/step - loss: 1.2262 - accuracy: 0.6921 - _timestamp: 1651798679.0000 - _runtime: 64.0000\n",
            "Epoch 2/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.8214 - accuracy: 0.7744 - _timestamp: 1651798731.0000 - _runtime: 116.0000\n",
            "Epoch 3/20\n",
            "267/267 [==============================] - 53s 197ms/step - loss: 0.4300 - accuracy: 0.8753 - _timestamp: 1651798784.0000 - _runtime: 169.0000\n",
            "Epoch 4/20\n",
            "267/267 [==============================] - 53s 198ms/step - loss: 0.2403 - accuracy: 0.9351 - _timestamp: 1651798837.0000 - _runtime: 222.0000\n",
            "Epoch 5/20\n",
            "267/267 [==============================] - 53s 197ms/step - loss: 0.1716 - accuracy: 0.9545 - _timestamp: 1651798889.0000 - _runtime: 274.0000\n",
            "Epoch 6/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.1458 - accuracy: 0.9611 - _timestamp: 1651798942.0000 - _runtime: 327.0000\n",
            "Epoch 7/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.1315 - accuracy: 0.9647 - _timestamp: 1651798994.0000 - _runtime: 379.0000\n",
            "Epoch 8/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.1224 - accuracy: 0.9669 - _timestamp: 1651799047.0000 - _runtime: 432.0000\n",
            "Epoch 9/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.1144 - accuracy: 0.9689 - _timestamp: 1651799099.0000 - _runtime: 484.0000\n",
            "Epoch 10/20\n",
            "267/267 [==============================] - 52s 197ms/step - loss: 0.1085 - accuracy: 0.9706 - _timestamp: 1651799151.0000 - _runtime: 536.0000\n",
            "Epoch 11/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.1030 - accuracy: 0.9721 - _timestamp: 1651799204.0000 - _runtime: 589.0000\n",
            "Epoch 12/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.0986 - accuracy: 0.9731 - _timestamp: 1651799256.0000 - _runtime: 641.0000\n",
            "Epoch 13/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.0946 - accuracy: 0.9742 - _timestamp: 1651799309.0000 - _runtime: 694.0000\n",
            "Epoch 14/20\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0911 - accuracy: 0.9751 - _timestamp: 1651799361.0000 - _runtime: 746.0000\n",
            "Epoch 15/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.0871 - accuracy: 0.9762 - _timestamp: 1651799413.0000 - _runtime: 798.0000\n",
            "Epoch 16/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.0839 - accuracy: 0.9770 - _timestamp: 1651799465.0000 - _runtime: 850.0000\n",
            "Epoch 17/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.0809 - accuracy: 0.9778 - _timestamp: 1651799518.0000 - _runtime: 903.0000\n",
            "Epoch 18/20\n",
            "267/267 [==============================] - 52s 196ms/step - loss: 0.0778 - accuracy: 0.9786 - _timestamp: 1651799570.0000 - _runtime: 955.0000\n",
            "Epoch 19/20\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0746 - accuracy: 0.9794 - _timestamp: 1651799622.0000 - _runtime: 1007.0000\n",
            "Epoch 20/20\n",
            "267/267 [==============================] - 52s 195ms/step - loss: 0.0723 - accuracy: 0.9799 - _timestamp: 1651799674.0000 - _runtime: 1059.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 64)     1728        ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 64)     3136        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (SimpleRNN)   [(None, None, 512),  295424      ['encoder_embedding[0][0]']      \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (SimpleRNN)   [(None, None, 512),  295424      ['decoder_embedding[0][0]',      \n",
            "                                 (None, 512)]                     'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 512),  524800      ['encoder_hidden_1[0][0]',       \n",
            "                                 (None, None, None)               'decoder_hidden_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 1024)   0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     50225       ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,170,737\n",
            "Trainable params: 1,170,737\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ed0616e7fef648afa6c32d6c1ee93dce",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▅▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▆▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.97992</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.07227</td></tr><tr><td>val_accuracy</td><td>0.57844</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">sandy-sweep-27</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/n6urd5er\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/n6urd5er</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20220506_005655-n6urd5er/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 6a5lrkq8 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: lstm\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220506_020420-6a5lrkq8</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/6a5lrkq8\" target=\"_blank\">atomic-sweep-30</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "267/267 [==============================] - 23s 72ms/step - loss: 1.3140 - accuracy: 0.6906 - _timestamp: 1651802692.0000 - _runtime: 31.0000\n",
            "Epoch 2/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.8603 - accuracy: 0.7573 - _timestamp: 1651802711.0000 - _runtime: 50.0000\n",
            "Epoch 3/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.7360 - accuracy: 0.7864 - _timestamp: 1651802730.0000 - _runtime: 69.0000\n",
            "Epoch 4/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.5694 - accuracy: 0.8377 - _timestamp: 1651802749.0000 - _runtime: 88.0000\n",
            "Epoch 5/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.3414 - accuracy: 0.9055 - _timestamp: 1651802768.0000 - _runtime: 107.0000\n",
            "Epoch 6/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.2427 - accuracy: 0.9347 - _timestamp: 1651802787.0000 - _runtime: 126.0000\n",
            "Epoch 7/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.2048 - accuracy: 0.9455 - _timestamp: 1651802806.0000 - _runtime: 145.0000\n",
            "Epoch 8/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1849 - accuracy: 0.9504 - _timestamp: 1651802825.0000 - _runtime: 164.0000\n",
            "Epoch 9/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1709 - accuracy: 0.9539 - _timestamp: 1651802844.0000 - _runtime: 183.0000\n",
            "Epoch 10/20\n",
            "267/267 [==============================] - 19s 73ms/step - loss: 0.1614 - accuracy: 0.9562 - _timestamp: 1651802863.0000 - _runtime: 202.0000\n",
            "Epoch 11/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1528 - accuracy: 0.9586 - _timestamp: 1651802882.0000 - _runtime: 221.0000\n",
            "Epoch 12/20\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 0.1464 - accuracy: 0.9605 - _timestamp: 1651802902.0000 - _runtime: 241.0000\n",
            "Epoch 13/20\n",
            "267/267 [==============================] - 19s 72ms/step - loss: 0.1409 - accuracy: 0.9619 - _timestamp: 1651802921.0000 - _runtime: 260.0000\n",
            "Epoch 14/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1355 - accuracy: 0.9634 - _timestamp: 1651802940.0000 - _runtime: 279.0000\n",
            "Epoch 15/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1317 - accuracy: 0.9643 - _timestamp: 1651802959.0000 - _runtime: 298.0000\n",
            "Epoch 16/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1277 - accuracy: 0.9654 - _timestamp: 1651802978.0000 - _runtime: 317.0000\n",
            "Epoch 17/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1245 - accuracy: 0.9661 - _timestamp: 1651802997.0000 - _runtime: 336.0000\n",
            "Epoch 18/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1211 - accuracy: 0.9672 - _timestamp: 1651803016.0000 - _runtime: 355.0000\n",
            "Epoch 19/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1180 - accuracy: 0.9680 - _timestamp: 1651803035.0000 - _runtime: 374.0000\n",
            "Epoch 20/20\n",
            "267/267 [==============================] - 19s 71ms/step - loss: 0.1157 - accuracy: 0.9686 - _timestamp: 1651803054.0000 - _runtime: 393.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 32)     864         ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 32)     1568        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (LSTM)        [(None, None, 64),   24832       ['encoder_embedding[0][0]']      \n",
            "                                 (None, 64),                                                      \n",
            "                                 (None, 64)]                                                      \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (LSTM)        [(None, None, 64),   24832       ['decoder_embedding[0][0]',      \n",
            "                                 (None, 64),                      'encoder_hidden_1[0][1]',       \n",
            "                                 (None, 64)]                      'encoder_hidden_1[0][2]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 64),   8256        ['encoder_hidden_1[0][0]',       \n",
            "                                 (None, None, None)               'decoder_hidden_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 128)    0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     6321        ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 66,673\n",
            "Trainable params: 66,673\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8d423ab4f83a46afb9a8b41f8985344d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▃▅▆▇▇█████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▅▅▄▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.96859</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.11572</td></tr><tr><td>val_accuracy</td><td>0.49392</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">atomic-sweep-30</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/6a5lrkq8\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/6a5lrkq8</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220506_020420-6a5lrkq8/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: v47f0d6d with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 25\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 512\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220506_030406-v47f0d6d</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/v47f0d6d\" target=\"_blank\">wild-sweep-33</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "267/267 [==============================] - 53s 184ms/step - loss: 1.1240 - accuracy: 0.7072 - _timestamp: 1651806308.0000 - _runtime: 62.0000\n",
            "Epoch 2/25\n",
            "267/267 [==============================] - 49s 182ms/step - loss: 0.7778 - accuracy: 0.7709 - _timestamp: 1651806356.0000 - _runtime: 110.0000\n",
            "Epoch 3/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.6182 - accuracy: 0.8177 - _timestamp: 1651806405.0000 - _runtime: 159.0000\n",
            "Epoch 4/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.3249 - accuracy: 0.9106 - _timestamp: 1651806454.0000 - _runtime: 208.0000\n",
            "Epoch 5/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.1808 - accuracy: 0.9521 - _timestamp: 1651806503.0000 - _runtime: 257.0000\n",
            "Epoch 6/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.1426 - accuracy: 0.9617 - _timestamp: 1651806551.0000 - _runtime: 305.0000\n",
            "Epoch 7/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.1236 - accuracy: 0.9666 - _timestamp: 1651806600.0000 - _runtime: 354.0000\n",
            "Epoch 8/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.1101 - accuracy: 0.9700 - _timestamp: 1651806649.0000 - _runtime: 403.0000\n",
            "Epoch 9/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.1000 - accuracy: 0.9726 - _timestamp: 1651806698.0000 - _runtime: 452.0000\n",
            "Epoch 10/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0912 - accuracy: 0.9749 - _timestamp: 1651806747.0000 - _runtime: 501.0000\n",
            "Epoch 11/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0832 - accuracy: 0.9769 - _timestamp: 1651806795.0000 - _runtime: 549.0000\n",
            "Epoch 12/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0756 - accuracy: 0.9789 - _timestamp: 1651806844.0000 - _runtime: 598.0000\n",
            "Epoch 13/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0695 - accuracy: 0.9806 - _timestamp: 1651806893.0000 - _runtime: 647.0000\n",
            "Epoch 14/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0636 - accuracy: 0.9822 - _timestamp: 1651806942.0000 - _runtime: 696.0000\n",
            "Epoch 15/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0578 - accuracy: 0.9838 - _timestamp: 1651806990.0000 - _runtime: 744.0000\n",
            "Epoch 16/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0527 - accuracy: 0.9852 - _timestamp: 1651807039.0000 - _runtime: 793.0000\n",
            "Epoch 17/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0477 - accuracy: 0.9865 - _timestamp: 1651807088.0000 - _runtime: 842.0000\n",
            "Epoch 18/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0432 - accuracy: 0.9877 - _timestamp: 1651807137.0000 - _runtime: 891.0000\n",
            "Epoch 19/25\n",
            "267/267 [==============================] - 49s 182ms/step - loss: 0.0390 - accuracy: 0.9889 - _timestamp: 1651807185.0000 - _runtime: 939.0000\n",
            "Epoch 20/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0354 - accuracy: 0.9899 - _timestamp: 1651807234.0000 - _runtime: 988.0000\n",
            "Epoch 21/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0318 - accuracy: 0.9909 - _timestamp: 1651807283.0000 - _runtime: 1037.0000\n",
            "Epoch 22/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0285 - accuracy: 0.9917 - _timestamp: 1651807332.0000 - _runtime: 1086.0000\n",
            "Epoch 23/25\n",
            "267/267 [==============================] - 49s 182ms/step - loss: 0.0263 - accuracy: 0.9924 - _timestamp: 1651807380.0000 - _runtime: 1134.0000\n",
            "Epoch 24/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0236 - accuracy: 0.9931 - _timestamp: 1651807429.0000 - _runtime: 1183.0000\n",
            "Epoch 25/25\n",
            "267/267 [==============================] - 49s 183ms/step - loss: 0.0218 - accuracy: 0.9936 - _timestamp: 1651807478.0000 - _runtime: 1232.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 32)     864         ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 32)     1568        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (GRU)         [(None, None, 512),  838656      ['encoder_embedding[0][0]']      \n",
            "                                 (None, 512)]                                                     \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (GRU)         [(None, None, 512),  838656      ['decoder_embedding[0][0]',      \n",
            "                                 (None, 512)]                     'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 512),  524800      ['encoder_hidden_1[0][0]',       \n",
            "                                 (None, None, None)               'decoder_hidden_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 1024)   0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     50225       ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 2,254,769\n",
            "Trainable params: 2,254,769\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f13788523514d63865262347efcdf45"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▃▄▆▇▇▇▇▇████████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▂▃▃▃▄▄▄▅▅▅▅▆▆▆▇▇▇▇██</td></tr><tr><td>loss</td><td>█▆▅▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99359</td></tr><tr><td>epoch</td><td>24</td></tr><tr><td>loss</td><td>0.02175</td></tr><tr><td>val_accuracy</td><td>0.57829</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">wild-sweep-33</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/v47f0d6d\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/v47f0d6d</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220506_030406-v47f0d6d/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 33804liz with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 256\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220506_041434-33804liz</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/33804liz\" target=\"_blank\">cosmic-sweep-35</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "267/267 [==============================] - 29s 92ms/step - loss: 0.9627 - accuracy: 0.7455 - _timestamp: 1651810511.0000 - _runtime: 37.0000\n",
            "Epoch 2/20\n",
            "267/267 [==============================] - 24s 92ms/step - loss: 0.3030 - accuracy: 0.9152 - _timestamp: 1651810535.0000 - _runtime: 61.0000\n",
            "Epoch 3/20\n",
            "267/267 [==============================] - 24s 91ms/step - loss: 0.1471 - accuracy: 0.9601 - _timestamp: 1651810560.0000 - _runtime: 86.0000\n",
            "Epoch 4/20\n",
            "267/267 [==============================] - 24s 92ms/step - loss: 0.1145 - accuracy: 0.9690 - _timestamp: 1651810584.0000 - _runtime: 110.0000\n",
            "Epoch 5/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.1015 - accuracy: 0.9725 - _timestamp: 1651810609.0000 - _runtime: 135.0000\n",
            "Epoch 6/20\n",
            "267/267 [==============================] - 25s 93ms/step - loss: 0.0924 - accuracy: 0.9747 - _timestamp: 1651810633.0000 - _runtime: 159.0000\n",
            "Epoch 7/20\n",
            "267/267 [==============================] - 24s 91ms/step - loss: 0.0847 - accuracy: 0.9768 - _timestamp: 1651810658.0000 - _runtime: 184.0000\n",
            "Epoch 8/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.0780 - accuracy: 0.9785 - _timestamp: 1651810682.0000 - _runtime: 208.0000\n",
            "Epoch 9/20\n",
            "267/267 [==============================] - 24s 92ms/step - loss: 0.0722 - accuracy: 0.9801 - _timestamp: 1651810707.0000 - _runtime: 233.0000\n",
            "Epoch 10/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.0666 - accuracy: 0.9816 - _timestamp: 1651810731.0000 - _runtime: 257.0000\n",
            "Epoch 11/20\n",
            "267/267 [==============================] - 24s 91ms/step - loss: 0.0616 - accuracy: 0.9830 - _timestamp: 1651810756.0000 - _runtime: 282.0000\n",
            "Epoch 12/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.0567 - accuracy: 0.9843 - _timestamp: 1651810780.0000 - _runtime: 306.0000\n",
            "Epoch 13/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.0522 - accuracy: 0.9856 - _timestamp: 1651810805.0000 - _runtime: 331.0000\n",
            "Epoch 14/20\n",
            "267/267 [==============================] - 24s 91ms/step - loss: 0.0480 - accuracy: 0.9867 - _timestamp: 1651810829.0000 - _runtime: 355.0000\n",
            "Epoch 15/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.0443 - accuracy: 0.9877 - _timestamp: 1651810854.0000 - _runtime: 380.0000\n",
            "Epoch 16/20\n",
            "267/267 [==============================] - 24s 91ms/step - loss: 0.0407 - accuracy: 0.9887 - _timestamp: 1651810878.0000 - _runtime: 404.0000\n",
            "Epoch 17/20\n",
            "267/267 [==============================] - 24s 92ms/step - loss: 0.0371 - accuracy: 0.9898 - _timestamp: 1651810903.0000 - _runtime: 429.0000\n",
            "Epoch 18/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.0340 - accuracy: 0.9906 - _timestamp: 1651810927.0000 - _runtime: 453.0000\n",
            "Epoch 19/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.0310 - accuracy: 0.9914 - _timestamp: 1651810952.0000 - _runtime: 478.0000\n",
            "Epoch 20/20\n",
            "267/267 [==============================] - 25s 92ms/step - loss: 0.0286 - accuracy: 0.9921 - _timestamp: 1651810976.0000 - _runtime: 502.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 256)    6912        ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 256)    12544       ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (GRU)         [(None, None, 256),  394752      ['encoder_embedding[0][0]']      \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (GRU)         [(None, None, 256),  394752      ['decoder_embedding[0][0]',      \n",
            "                                 (None, 256)]                     'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 256),  131328      ['encoder_hidden_1[0][0]',       \n",
            "                                 (None, None, None)               'decoder_hidden_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 512)    0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     25137       ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 965,425\n",
            "Trainable params: 965,425\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "606f728ee651472c94a8b2d888a3c571"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>▁▆▇▇▇███████████████</td></tr><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>accuracy</td><td>0.99212</td></tr><tr><td>epoch</td><td>19</td></tr><tr><td>loss</td><td>0.02857</td></tr><tr><td>val_accuracy</td><td>0.55149</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Synced <strong style=\"color:#cdcd00\">cosmic-sweep-35</strong>: <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/33804liz\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/33804liz</a><br/>Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20220506_041434-33804liz/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 9kyojznr with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: gru\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.16"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20220506_051325-9kyojznr</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/runs/9kyojznr\" target=\"_blank\">quiet-sweep-39</a></strong> to <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>Sweep page:  <a href=\"https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7\" target=\"_blank\">https://wandb.ai/hithesh-sidhesh/CS6910-Assignment_3-sweep-Tamil/sweeps/bygbvpb7</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "267/267 [==============================] - 24s 75ms/step - loss: 1.1631 - accuracy: 0.7123 - _timestamp: 1651814037.0000 - _runtime: 32.0000\n",
            "Epoch 2/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.7614 - accuracy: 0.7753 - _timestamp: 1651814057.0000 - _runtime: 52.0000\n",
            "Epoch 3/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.5564 - accuracy: 0.8406 - _timestamp: 1651814076.0000 - _runtime: 71.0000\n",
            "Epoch 4/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.2191 - accuracy: 0.9406 - _timestamp: 1651814096.0000 - _runtime: 91.0000\n",
            "Epoch 5/20\n",
            "267/267 [==============================] - 20s 73ms/step - loss: 0.1612 - accuracy: 0.9567 - _timestamp: 1651814116.0000 - _runtime: 111.0000\n",
            "Epoch 6/20\n",
            "267/267 [==============================] - 20s 73ms/step - loss: 0.1398 - accuracy: 0.9624 - _timestamp: 1651814135.0000 - _runtime: 130.0000\n",
            "Epoch 7/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.1273 - accuracy: 0.9658 - _timestamp: 1651814155.0000 - _runtime: 150.0000\n",
            "Epoch 8/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.1178 - accuracy: 0.9681 - _timestamp: 1651814175.0000 - _runtime: 170.0000\n",
            "Epoch 9/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.1113 - accuracy: 0.9697 - _timestamp: 1651814194.0000 - _runtime: 189.0000\n",
            "Epoch 10/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.1056 - accuracy: 0.9712 - _timestamp: 1651814214.0000 - _runtime: 209.0000\n",
            "Epoch 11/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.1010 - accuracy: 0.9722 - _timestamp: 1651814234.0000 - _runtime: 229.0000\n",
            "Epoch 12/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.0970 - accuracy: 0.9733 - _timestamp: 1651814254.0000 - _runtime: 249.0000\n",
            "Epoch 13/20\n",
            "267/267 [==============================] - 20s 73ms/step - loss: 0.0929 - accuracy: 0.9743 - _timestamp: 1651814273.0000 - _runtime: 268.0000\n",
            "Epoch 14/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.0896 - accuracy: 0.9751 - _timestamp: 1651814293.0000 - _runtime: 288.0000\n",
            "Epoch 15/20\n",
            "267/267 [==============================] - 20s 73ms/step - loss: 0.0864 - accuracy: 0.9758 - _timestamp: 1651814312.0000 - _runtime: 307.0000\n",
            "Epoch 16/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.0837 - accuracy: 0.9766 - _timestamp: 1651814332.0000 - _runtime: 327.0000\n",
            "Epoch 17/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.0808 - accuracy: 0.9775 - _timestamp: 1651814352.0000 - _runtime: 347.0000\n",
            "Epoch 18/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.0783 - accuracy: 0.9782 - _timestamp: 1651814372.0000 - _runtime: 367.0000\n",
            "Epoch 19/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.0759 - accuracy: 0.9788 - _timestamp: 1651814391.0000 - _runtime: 386.0000\n",
            "Epoch 20/20\n",
            "267/267 [==============================] - 20s 74ms/step - loss: 0.0734 - accuracy: 0.9795 - _timestamp: 1651814411.0000 - _runtime: 406.0000\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " decoder_input (InputLayer)     [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " encoder_embedding (Embedding)  (None, None, 64)     1728        ['encoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " decoder_embedding (Embedding)  (None, None, 64)     3136        ['decoder_input[0][0]']          \n",
            "                                                                                                  \n",
            " encoder_hidden_1 (GRU)         [(None, None, 128),  74496       ['encoder_embedding[0][0]']      \n",
            "                                 (None, 128)]                                                     \n",
            "                                                                                                  \n",
            " decoder_hidden_1 (GRU)         [(None, None, 128),  74496       ['decoder_embedding[0][0]',      \n",
            "                                 (None, 128)]                     'encoder_hidden_1[0][1]']       \n",
            "                                                                                                  \n",
            " attention_1 (AttentionLayer)   ((None, None, 128),  32896       ['encoder_hidden_1[0][0]',       \n",
            "                                 (None, None, None)               'decoder_hidden_1[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concat_layer_1 (Concatenate)   (None, None, 256)    0           ['decoder_hidden_1[0][0]',       \n",
            "                                                                  'attention_1[0][0]']            \n",
            "                                                                                                  \n",
            " decoder_output (Dense)         (None, None, 49)     12593       ['concat_layer_1[0][0]']         \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 199,345\n",
            "Trainable params: 199,345\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#sweep_id = wandb.sweep(sweep_config, project=\"CS6910-Assignment_3-sweep-Tamil\")\n",
        "sweep_id = \"bygbvpb7\"\n",
        "wandb.agent(sweep_id, main,project=\"CS6910-Assignment_3-sweep-Tamil\",entity=\"hithesh-sidhesh\",count = 12)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model on Test data"
      ],
      "metadata": {
        "id": "9z9gBGK79OC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 25\n",
        "embedding_size = 64\n",
        "cell_type = 'gru'\n",
        "dropout = 0.2\n",
        "encoder_layers = 1\n",
        "decoder_layers = 1\n",
        "hidden_layer_size = 256\n",
        "batch_size = 256"
      ],
      "metadata": {
        "id": "c_EwTGPK9Zhg"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "TI3NXDyk_mWU"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YGW-nLt5_mpb"
      },
      "outputs": [],
      "source": [
        "#Embedding test data\n",
        "x_test = test['English'].values\n",
        "y_test = test['Tamil'].values\n",
        "# We use \"tab\" as the \"start sequence\" character for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "y_test = \"\\t\"+y_test+\"\\n\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "AKRlpGsC_mpc"
      },
      "outputs": [],
      "source": [
        "#reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "#reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0be447a6-4dd9-46d4-8f5e-9fb31be82002",
        "id": "QZGBoXpA_mpc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in test set: 6864\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 49\n",
            "Max sequence length for test inputs: 23\n",
            "Max sequence length for test outputs: 24\n",
            "{'a': 0, 'b': 1, 'c': 2, 'd': 3, 'e': 4, 'f': 5, 'g': 6, 'h': 7, 'i': 8, 'j': 9, 'k': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'w': 22, 'x': 23, 'y': 24, 'z': 25, ' ': 26}\n",
            "{'\\t': 0, '\\n': 1, 'ஃ': 2, 'அ': 3, 'ஆ': 4, 'இ': 5, 'ஈ': 6, 'உ': 7, 'ஊ': 8, 'எ': 9, 'ஏ': 10, 'ஐ': 11, 'ஒ': 12, 'ஓ': 13, 'க': 14, 'ங': 15, 'ச': 16, 'ஜ': 17, 'ஞ': 18, 'ட': 19, 'ண': 20, 'த': 21, 'ந': 22, 'ன': 23, 'ப': 24, 'ம': 25, 'ய': 26, 'ர': 27, 'ற': 28, 'ல': 29, 'ள': 30, 'ழ': 31, 'வ': 32, 'ஷ': 33, 'ஸ': 34, 'ஹ': 35, 'ா': 36, 'ி': 37, 'ீ': 38, 'ு': 39, 'ூ': 40, 'ெ': 41, 'ே': 42, 'ை': 43, 'ொ': 44, 'ோ': 45, 'ௌ': 46, '்': 47, ' ': 48}\n"
          ]
        }
      ],
      "source": [
        "test_input_characters = set()\n",
        "test_target_characters = set()\n",
        "\n",
        "for i in range(len(x_test)):\n",
        "  test_input_characters.update(list(str(x_test[i])))\n",
        "  test_target_characters.update(list(str(y_test[i])))\n",
        "\n",
        "  # input_characters=list(set(input_characters+list(str(x[i]))))\n",
        "  # target_characters=list(set(target_characters+list(str(y[i]))))\n",
        "\n",
        "test_input_characters = sorted(list(test_input_characters))\n",
        "test_target_characters = sorted(list(test_target_characters))\n",
        "\n",
        "# add the space character to both\n",
        "test_input_characters.append(\" \")\n",
        "test_target_characters.append(\" \")\n",
        "\n",
        "test_num_encoder_tokens = len(test_input_characters)\n",
        "test_num_decoder_tokens = len(test_target_characters)\n",
        "\n",
        "test_input_length=[]\n",
        "test_target_length=[]\n",
        "for i in range(len(x_test)):\n",
        "  test_input_length.append(len(str(x_test[i])))\n",
        "  test_target_length.append(len(str(y_test[i])))\n",
        "\n",
        "test_max_encoder_seq_length = max(test_input_length)\n",
        "test_max_decoder_seq_length = max(test_target_length)\n",
        "\n",
        "print(\"Number of samples in test set:\", len(x_test))\n",
        "print(\"Number of unique input tokens:\", test_num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", test_num_decoder_tokens)\n",
        "print(\"Max sequence length for test inputs:\", test_max_encoder_seq_length)\n",
        "print(\"Max sequence length for test outputs:\", test_max_decoder_seq_length)\n",
        "\n",
        "test_input_token_index = dict([(char, i) for i, char in enumerate(test_input_characters)])\n",
        "test_target_token_index = dict([(char, i) for i, char in enumerate(test_target_characters)])\n",
        "print(test_input_token_index)\n",
        "print(test_target_token_index)\n",
        "\n",
        "test_encoder_input_data = np.zeros((len(x_test), test_max_encoder_seq_length,test_num_encoder_tokens), dtype=\"float32\")\n",
        "test_decoder_input_data = np.zeros((len(x_test), test_max_decoder_seq_length,test_num_decoder_tokens), dtype=\"float32\")\n",
        "test_decoder_target_data = np.zeros((len(x), max_decoder_seq_length, test_num_decoder_tokens), dtype=\"float32\")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(x_test, y_test)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        test_encoder_input_data[i, t ,input_token_index[char]] = 1.0\n",
        "    test_encoder_input_data[i, t + 1 :,input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        test_decoder_input_data[i, t ,target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            test_decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    test_decoder_input_data[i, t + 1 :,target_token_index[\" \"]] = 1.0\n",
        "    test_decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2096ade-bf30-41ca-f7ea-c98fb48646f7",
        "id": "gIAY_fq9_mpc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(68215, 30)\n"
          ]
        }
      ],
      "source": [
        "# Using label encoding for the encoder inputs (and then find an embedding using the Embedding layer)\n",
        "encoder_input_data = np.argmax(encoder_input_data, axis=2)\n",
        "test_encoder_input_data = np.argmax(test_encoder_input_data, axis=2)\n",
        "#test_encoder_input_data = np.argmax(test_encoder_input_data, axis=2)\n",
        "print(encoder_input_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xeFcuwdq_mpd"
      },
      "outputs": [],
      "source": [
        "decoder_input_data = np.argmax(decoder_input_data, axis=2)\n",
        "test_decoder_input_data = np.argmax(test_decoder_input_data, axis=2)\n",
        "#test_decoder_input_data = np.argmax(test_decoder_input_array, axis=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train the model\n",
        "model = create_model(num_encoder_tokens=num_encoder_tokens,embedding_size=embedding_size,cell_type = cell_type,\n",
        "                  latent_dimension=hidden_layer_size,\n",
        "                  dropout=dropout,number_of_encoder_layers = encoder_layers,num_decoder_tokens=num_decoder_tokens,\n",
        "                  number_of_decoder_layers=decoder_layers)\n",
        "\n",
        "\n",
        "encoder_model , decoder_model = fit(model=model,cell_type=cell_type,encoder_input_data=encoder_input_data, \n",
        "                                decoder_input_data=decoder_input_data,\n",
        "      decoder_target_data=decoder_target_data,batch_size=batch_size,epochs=epochs,\n",
        "      number_of_encoder_layers = 1,number_of_decoder_layers=1 ,latent_dimension=hidden_layer_size)\n",
        "\n",
        "# Inference for Test Data\n",
        "test_accuracy, heatmaps = infer(model, test_encoder_input_data, test_input_words, test_target_words, num_decoder_tokens, max_decoder_seq_length, target_token_index, reverse_target_char_index, hidden_layer_size, cell_type, for_test = True)\n",
        "#wandb.log( {'val_accuracy': test_accuracy})\n",
        "#run.finish()\n",
        "# Inference for Test Data\n",
        "# test_accuracy, heatmaps = attention_inference.infer(encoder_test_input_data, test_input_words, test_target_words, num_decoder_characters, max_decoder_seq_length, target_characters_index, inverse_target_characters_index, latent_dim, cell_type)\n",
        "# wandb.log( { \"test_accuracy\": test_accuracy} )\n",
        "\n",
        "#for i, heatmap in enumerate(heatmaps):\n",
        "    #wandb.log( {\"heatmap_\" + str(i): heatmap})\n",
        "#run.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuU2TuJYCb7u",
        "outputId": "4bccd686-641e-4e52-fb93-d3616ad84a9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "267/267 [==============================] - 391s 1s/step - loss: 1.0734 - accuracy: 0.7218\n",
            "Epoch 2/25\n",
            "267/267 [==============================] - 376s 1s/step - loss: 0.7013 - accuracy: 0.7927\n",
            "Epoch 3/25\n",
            "267/267 [==============================] - 374s 1s/step - loss: 0.3533 - accuracy: 0.9008\n",
            "Epoch 4/25\n",
            "267/267 [==============================] - 376s 1s/step - loss: 0.1729 - accuracy: 0.9533\n",
            "Epoch 5/25\n",
            "267/267 [==============================] - 374s 1s/step - loss: 0.1377 - accuracy: 0.9628\n",
            "Epoch 6/25\n",
            " 96/267 [=========>....................] - ETA: 3:58 - loss: 0.1245 - accuracy: 0.9661"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "visualize_connectivity(10)\n",
        "visualize_lstm(10, 0)"
      ],
      "metadata": {
        "id": "_iMMDf9gXt17"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Asg_3_with_attention.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1c9ea1f56adf432f89f21f594f46a527": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_219a61e985ec43d497ad912a259ddba4",
              "IPY_MODEL_18aefa16df2d4974b7e529f806650561"
            ],
            "layout": "IPY_MODEL_a7a886c030624021b4d84e133e2290d7"
          }
        },
        "219a61e985ec43d497ad912a259ddba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f38c236f8cc476fb1266bf83ad718fd",
            "placeholder": "​",
            "style": "IPY_MODEL_41d00627641e4f27a654c11f91dde817",
            "value": "0.017 MB of 0.017 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "18aefa16df2d4974b7e529f806650561": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3208e3bf06444f349b55e6dab4ee6f77",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2b00f8e0c504c09bda814f9b1375959",
            "value": 1
          }
        },
        "a7a886c030624021b4d84e133e2290d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f38c236f8cc476fb1266bf83ad718fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d00627641e4f27a654c11f91dde817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3208e3bf06444f349b55e6dab4ee6f77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2b00f8e0c504c09bda814f9b1375959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8644725cdfa04bb4861baed088695de4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6ff97bb4b064699b5e0c8179b9c27ab",
              "IPY_MODEL_92a3f5aeced8472d8d2d880206cd2aa8"
            ],
            "layout": "IPY_MODEL_88150d3d06c94fb38d6ed45f2367d30e"
          }
        },
        "c6ff97bb4b064699b5e0c8179b9c27ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f0248d6cd954a2aac8179b70f724621",
            "placeholder": "​",
            "style": "IPY_MODEL_62d01b43cecf4fb6a97b78358b97a8ec",
            "value": "0.016 MB of 0.016 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "92a3f5aeced8472d8d2d880206cd2aa8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23e2baba27144bffa18aa914064d79c2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f92dda85254f406cb87f4ceaeeba56c6",
            "value": 1
          }
        },
        "88150d3d06c94fb38d6ed45f2367d30e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f0248d6cd954a2aac8179b70f724621": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d01b43cecf4fb6a97b78358b97a8ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23e2baba27144bffa18aa914064d79c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f92dda85254f406cb87f4ceaeeba56c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8628284d49b84c99baf17b7e69b11004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa1ef101b69044789b157de59ea35cf8",
              "IPY_MODEL_9cec9012c841482795ba31d53b4d0b53"
            ],
            "layout": "IPY_MODEL_7a70aa911811470d9df51c25389f5692"
          }
        },
        "aa1ef101b69044789b157de59ea35cf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f41145bfbeb24d42b2c15344b7199d16",
            "placeholder": "​",
            "style": "IPY_MODEL_c9fc68183f4d4b2a915005c6db4b175a",
            "value": "0.016 MB of 0.016 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9cec9012c841482795ba31d53b4d0b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dcaa7f9d48bb43579327c726d6689622",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6b66ef4907b4496f9d0aabc774ca4c18",
            "value": 1
          }
        },
        "7a70aa911811470d9df51c25389f5692": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f41145bfbeb24d42b2c15344b7199d16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9fc68183f4d4b2a915005c6db4b175a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dcaa7f9d48bb43579327c726d6689622": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6b66ef4907b4496f9d0aabc774ca4c18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1d3a3726c6f34b108d3d06da1937469a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa98a80109d745d9aecc98b468e14a36",
              "IPY_MODEL_a2cdff9f9d4e4b65aaee0767d08e0e68"
            ],
            "layout": "IPY_MODEL_488b6a59ce4944308fa01ea5e53ef51a"
          }
        },
        "aa98a80109d745d9aecc98b468e14a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df4c74f942084aa59ba4a50b0e59d568",
            "placeholder": "​",
            "style": "IPY_MODEL_a216d2e70d584f16aa310d53cb1b78e8",
            "value": "0.017 MB of 0.017 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "a2cdff9f9d4e4b65aaee0767d08e0e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c80f8569c14ffba23229e1fa69a14a",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1795d935b06d47f08f269cecd12b007b",
            "value": 1
          }
        },
        "488b6a59ce4944308fa01ea5e53ef51a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4c74f942084aa59ba4a50b0e59d568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a216d2e70d584f16aa310d53cb1b78e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c80f8569c14ffba23229e1fa69a14a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1795d935b06d47f08f269cecd12b007b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ab19b28682cd4098a467898a2ec9d315": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01f9696041f2480b8acfab66e1ce4101",
              "IPY_MODEL_9b06c266558248cfa9f56f145ee3b8f6"
            ],
            "layout": "IPY_MODEL_190ce0e5018b40ad8c81e27139f9fd03"
          }
        },
        "01f9696041f2480b8acfab66e1ce4101": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c5e4a0a408b44768ddb94ccabdd7421",
            "placeholder": "​",
            "style": "IPY_MODEL_8a89f67ebc2c4a7096919df0978ea529",
            "value": "0.016 MB of 0.016 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9b06c266558248cfa9f56f145ee3b8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a36b77bf27a458791500e0b82effdf0",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_468fef44bc50415584357bdfbf69c605",
            "value": 1
          }
        },
        "190ce0e5018b40ad8c81e27139f9fd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c5e4a0a408b44768ddb94ccabdd7421": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a89f67ebc2c4a7096919df0978ea529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0a36b77bf27a458791500e0b82effdf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "468fef44bc50415584357bdfbf69c605": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bd80377e237d4ad484f690247286696d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c49eed8576a46e7bd4da29c68e5397f",
              "IPY_MODEL_e5a57b4eedea4c65bc3faea48a09dd2c"
            ],
            "layout": "IPY_MODEL_88bcc30646504cafb16fe1bee8042ddb"
          }
        },
        "3c49eed8576a46e7bd4da29c68e5397f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c716ed834bc47859cc9a5b995bbd16c",
            "placeholder": "​",
            "style": "IPY_MODEL_081658dbd3f6402a85ce0fd16ed0e003",
            "value": "0.018 MB of 0.018 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e5a57b4eedea4c65bc3faea48a09dd2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c220b4425c3c472ca0b1d8faeb7bd5ea",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_114ca715b4c849099d1fb90bbe9a2602",
            "value": 1
          }
        },
        "88bcc30646504cafb16fe1bee8042ddb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c716ed834bc47859cc9a5b995bbd16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "081658dbd3f6402a85ce0fd16ed0e003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c220b4425c3c472ca0b1d8faeb7bd5ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "114ca715b4c849099d1fb90bbe9a2602": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ed0616e7fef648afa6c32d6c1ee93dce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_425505df75d446c9bf9b88ec11d923e5",
              "IPY_MODEL_e43c55cd7874465f9e0607cdfbc16637"
            ],
            "layout": "IPY_MODEL_8e253b72680e47e4a5581381f1f3c4c4"
          }
        },
        "425505df75d446c9bf9b88ec11d923e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_46dfcd7d9f0046c5bc1b41dd9c6bc700",
            "placeholder": "​",
            "style": "IPY_MODEL_9d420c7814c94bf8a841b9177c183657",
            "value": "0.015 MB of 0.015 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e43c55cd7874465f9e0607cdfbc16637": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3087b49485c4020bcc2e798569698ab",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_00051e10474c4451bd6a49eaa8570ad6",
            "value": 1
          }
        },
        "8e253b72680e47e4a5581381f1f3c4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46dfcd7d9f0046c5bc1b41dd9c6bc700": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d420c7814c94bf8a841b9177c183657": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3087b49485c4020bcc2e798569698ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "00051e10474c4451bd6a49eaa8570ad6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d423ab4f83a46afb9a8b41f8985344d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2afc8c0033774e0392106ec082bfea15",
              "IPY_MODEL_e09f7b3851424d18a35f098e2a527931"
            ],
            "layout": "IPY_MODEL_da86a62d10dd49b7992379e36c575641"
          }
        },
        "2afc8c0033774e0392106ec082bfea15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f9b233a45a0439496fc84d3a85423b1",
            "placeholder": "​",
            "style": "IPY_MODEL_6283d4bebe6d41958fc91906268bcbb3",
            "value": "0.015 MB of 0.015 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "e09f7b3851424d18a35f098e2a527931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_909fd189136547ef843a1b8747b57eed",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_40f20c75aa494cbbaa2bc541a3529ba4",
            "value": 1
          }
        },
        "da86a62d10dd49b7992379e36c575641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9b233a45a0439496fc84d3a85423b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6283d4bebe6d41958fc91906268bcbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "909fd189136547ef843a1b8747b57eed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40f20c75aa494cbbaa2bc541a3529ba4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2f13788523514d63865262347efcdf45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f1879a21ebf94046abc7cd54fa6cd57d",
              "IPY_MODEL_1322e9884ced40d99f8af68f46a61c24"
            ],
            "layout": "IPY_MODEL_bc6084fbaa4c46f7be95357660f3f70b"
          }
        },
        "f1879a21ebf94046abc7cd54fa6cd57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f6c736d10224763ba1b3ce475545cd9",
            "placeholder": "​",
            "style": "IPY_MODEL_8085941d0dcf4c848282193d57cf80bd",
            "value": "0.016 MB of 0.016 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "1322e9884ced40d99f8af68f46a61c24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_179ffee7a6dd473e9cc97ffe071080d9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_434a7cfab0b742c782065a802abd2294",
            "value": 1
          }
        },
        "bc6084fbaa4c46f7be95357660f3f70b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f6c736d10224763ba1b3ce475545cd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8085941d0dcf4c848282193d57cf80bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "179ffee7a6dd473e9cc97ffe071080d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "434a7cfab0b742c782065a802abd2294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "606f728ee651472c94a8b2d888a3c571": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f28c694a86c04491a04102a9ae46e853",
              "IPY_MODEL_16f7b593df734eec9b4d076c67a565e9"
            ],
            "layout": "IPY_MODEL_3cf743b62ca5461184647623bb1fab02"
          }
        },
        "f28c694a86c04491a04102a9ae46e853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c415a29c3d8647beb755a4ee2aba8fa4",
            "placeholder": "​",
            "style": "IPY_MODEL_4103604fa7db424da59214be0b74ff22",
            "value": "0.015 MB of 0.015 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "16f7b593df734eec9b4d076c67a565e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667aa2575793404898881c65e3bfac33",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cfe07d8be5fe476183fb8d825993fdb6",
            "value": 1
          }
        },
        "3cf743b62ca5461184647623bb1fab02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c415a29c3d8647beb755a4ee2aba8fa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4103604fa7db424da59214be0b74ff22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "667aa2575793404898881c65e3bfac33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfe07d8be5fe476183fb8d825993fdb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}